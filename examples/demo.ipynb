{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.models.bart.comet_bart import COMETBART\n",
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.models.base import KnowledgeModel\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "model: KnowledgeModel = COMETBART.from_pretrained(\"/Users/mismayil/Desktop/EPFL/nlplab/comet-atomic-2020/comet-atomic_2020_BART\")\n",
    "csi = CommonsenseInference()\n",
    "text = \"Gabby always brought cookies to school. But at lunch, everyone wanted them. And she had a hard time saying no. Gabby began to hate the other students. And at lunch, she ate far away from everyone.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, model, model_args={\"num_generate\": 3, \"batch_size\": 128})\n",
    "kgraph.to_jsonl(\"kgraph2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.remove_processor(\"noun_phrase_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.head import KnowledgeHeadExtractor, KnowledgeHead, KnowledgeHeadType\n",
    "from typing import Optional, List\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "import spacy\n",
    "\n",
    "class NounHeadExtractor(KnowledgeHeadExtractor):\n",
    "    def extract(self, text: str, doc: Optional[Doc] = None) -> List[KnowledgeHead]:\n",
    "        if not doc:\n",
    "            doc = self.lang(text)\n",
    "\n",
    "        heads = []\n",
    "\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\":\n",
    "                heads.append(KnowledgeHead(text=token.text, type=KnowledgeHeadType.NOUN_PHRASE, entity=token))\n",
    "        \n",
    "        return heads\n",
    "\n",
    "noun_extractor = NounHeadExtractor(\"noun_extractor\", spacy.load(\"en_core_web_sm\"))\n",
    "csi.add_processor(noun_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.bart.comet_bart import COMETBART\n",
    "from kogito.models.base import KnowledgeModel\n",
    "\n",
    "csi = CommonsenseInference()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True)\n",
    "kgraph.to_jsonl(\"kgraph_dry_run.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"I wanted to feed him. he didnt listen to me\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True)\n",
    "kgraph.to_jsonl(\"kgraph_dry_run_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kogito.core.relation import OBJECT_USE, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, relations=[OBJECT_USE, CAUSES])\n",
    "kgraph.to_jsonl(\"kgraph_rel_subset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Head extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, extract_heads=False)\n",
    "kgraph.to_jsonl(\"kgraph_no_head_extract.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Relation matching and no subset of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No relation found to match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mismayil/Desktop/EPFL/nlplab/kogito/examples/demo.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mismayil/Desktop/EPFL/nlplab/kogito/examples/demo.ipynb#ch0000018?line=0'>1</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGabby always brought cookies to school.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mismayil/Desktop/EPFL/nlplab/kogito/examples/demo.ipynb#ch0000018?line=1'>2</a>\u001b[0m kgraph: KnowledgeGraph \u001b[39m=\u001b[39m csi\u001b[39m.\u001b[39;49minfer(text, dry_run\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, match_relations\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/EPFL/nlplab/kogito/kogito/inference.py:97\u001b[0m, in \u001b[0;36mCommonsenseInference.infer\u001b[0;34m(self, text, model, heads, model_args, extract_heads, match_relations, relations, dry_run)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/mismayil/Desktop/EPFL/nlplab/kogito/kogito/inference.py?line=94'>95</a>\u001b[0m     head_relations\u001b[39m.\u001b[39mextend(\u001b[39mlist\u001b[39m(product(kg_heads, relations)))\n\u001b[1;32m     <a href='file:///Users/mismayil/Desktop/EPFL/nlplab/kogito/kogito/inference.py?line=95'>96</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///Users/mismayil/Desktop/EPFL/nlplab/kogito/kogito/inference.py?line=96'>97</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo relation found to match\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///Users/mismayil/Desktop/EPFL/nlplab/kogito/kogito/inference.py?line=98'>99</a>\u001b[0m kg_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///Users/mismayil/Desktop/EPFL/nlplab/kogito/kogito/inference.py?line=100'>101</a>\u001b[0m \u001b[39mfor\u001b[39;00m head_relation \u001b[39min\u001b[39;00m head_relations:\n",
      "\u001b[0;31mValueError\u001b[0m: No relation found to match"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, match_relations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Relation matching with subset of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n"
     ]
    }
   ],
   "source": [
    "from kogito.core.relation import DESIRES, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, match_relations=False, relations=[CAUSES, DESIRES])\n",
    "kgraph.to_jsonl(\"kgraph_no_match_subset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Head extraction, no Relation matching with subset of relations (hence, ultimate manual specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.relation import DESIRES, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, extract_heads=False, match_relations=False, relations=[CAUSES, DESIRES])\n",
    "kgraph.to_jsonl(\"kgraph_manual.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"post office\", \"to get out of the room\"], dry_run=True)\n",
    "kgraph.to_jsonl(\"kgraph_manual_heads.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation matching (SWEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n",
      "Took 0.5735430717468262 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import SWEMRelationMatcher\n",
    "from kogito.models.bart.comet_bart import COMETBART\n",
    "from kogito.models.base import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "swem_matcher = SWEMRelationMatcher(\"swem_relation_matcher\")\n",
    "csi.add_processor(swem_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"/Users/mismayil/Desktop/EPFL/nlplab/comet-atomic-2020/comet-atomic_2020_BART\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"kgraph_modelbased_relations_swem.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation matching (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp8py0dxx_\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp8py0dxx_/_remote_module_non_sriptable.py\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /distilbert-base-uncased/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1584: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  rank_zero_warn(\n",
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fd4798b61e45d58671961cd2663c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4.495680809020996 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import DistilBertRelationMatcher\n",
    "from kogito.models.base import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "dbert_matcher = DistilBertRelationMatcher(\"dbert_relation_matcher\")\n",
    "csi.add_processor(dbert_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"/Users/mismayil/Desktop/EPFL/nlplab/comet-atomic-2020/comet-atomic_2020_BART\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"kgraph_modelbased_relations_dbert.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3 Based Commonsense Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n",
      "Generating commonsense graph...\n",
      "Took 1.9707791805267334 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3 import GPT3Zeroshot\n",
    "import time, os\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "model = GPT3Zeroshot(api_key=\"\", model_name=\"text-davinci-002\")\n",
    "sample_graph = KnowledgeGraph.from_csv(\"sample_graph.tsv\", sep=\"\\t\", header=None)\n",
    "heads = [\"PersonX accuses PersonY of cheating\", \"PersonX aces PersonX's exam\"]\n",
    "\n",
    "start = time.time()\n",
    "kgraph = csi.infer(model=model, heads=heads, sample_graph=sample_graph, model_args={\"debug\": True})\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"kgraph_gpt3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3 Based Commonsense Inference with custom relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n",
      "Generating commonsense graph...\n",
      "Took 1.8346340656280518 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3 import GPT3Zeroshot\n",
    "from kogito.core.relation import KnowledgeRelation, register_relation\n",
    "import time, os\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "def x_want2_verbalizer(head, **kwargs):\n",
    "    index = kwargs.get(\"index\")\n",
    "    index_txt = f\"{index}\" if index is not None else \"\"\n",
    "    return f\"Situation {index_txt}: {head}\\nWants: As a result, PersonX wants\"\n",
    "\n",
    "X_WANT2 = KnowledgeRelation(\"xWant2\",\n",
    "                            verbalizer=x_want2_verbalizer,\n",
    "                            prompt=\"How does this situation affect each character's wants?\")\n",
    "register_relation(X_WANT2)\n",
    "\n",
    "model = GPT3Zeroshot(api_key=\"\", model_name=\"text-davinci-002\")\n",
    "\n",
    "sample_graph = KnowledgeGraph.from_csv(\"sample_graph2.tsv\", sep=\"\\t\", header=None)\n",
    "\n",
    "heads = [\"PersonX makes a huge mistake\", \"PersonX sees PersonY's point\"]\n",
    "\n",
    "start = time.time()\n",
    "kgraph = csi.infer(model=model,\n",
    "                   heads=heads,\n",
    "                   sample_graph=sample_graph,\n",
    "                   model_args={\"debug\": True})\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"kgraph_gpt3_custom_relation.json\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
