{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n",
      "Matching knowledge heads with relations...\n",
      "Generating knowledge graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from kogito.models.bart.comet import COMETBART\n",
    "from kogito.inference import CommonsenseInference\n",
    "\n",
    "# Load pre-trained model from HuggingFace\n",
    "model = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "\n",
    "# Initialize inference module with a spacy language pipeline\n",
    "csi = CommonsenseInference(language=\"en_core_web_sm\")\n",
    "\n",
    "# Run inference\n",
    "text = \"PersonX becomes a great basketball player\"\n",
    "kgraph = csi.infer(text, model)\n",
    "\n",
    "# Save output knowledge graph to JSON file\n",
    "kgraph.to_jsonl(\"results/kgraph.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.head import KnowledgeHead\n",
    "from kogito.core.knowledge import Knowledge\n",
    "from kogito.core.relation import X_NEED\n",
    "\n",
    "head = KnowledgeHead(\"PersonX buys lunch\")\n",
    "knowledge = Knowledge(head=head, relation=X_NEED, tails=[\"bring a wallet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.knowledge import Knowledge, KnowledgeGraph\n",
    "from kogito.core.head import KnowledgeHead\n",
    "from kogito.core.relation import X_NEED, CAUSES\n",
    "\n",
    "knowledge1 = Knowledge(head=KnowledgeHead(\"PersonX buys lunch\"), relation=X_NEED, tails=[\"bring a wallet\"])\n",
    "knowledge2 = Knowledge(head=KnowledgeHead(\"Throwing a party\"), relation=CAUSES, tails=[\"have fun\"])\n",
    "\n",
    "kgraph = KnowledgeGraph([knowledge1, knowledge2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge(head=\"PersonX buys lunch\", relation=\"xNeed\", tails=['bring a wallet'])\n",
      "Knowledge(head=\"Throwing a party\", relation=\"Causes\", tails=['have fun'])\n"
     ]
    }
   ],
   "source": [
    "for knowledge in kgraph:\n",
    "    print(knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From csv\n",
    "kgraph1 = KnowledgeGraph.from_csv(\"sample_graph.tsv\", sep=\"\\t\", header=None)\n",
    "\n",
    "# From jsonl (list of json objects)\n",
    "kgraph2 = KnowledgeGraph.from_jsonl(\"sample_graph.jsonl\", head_attr=\"source\", relation_attr=\"rel\", tails_attr=\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union\n",
    "kgraph3 = kgraph1 + kgraph2 # kgraph1.union(kgraph2)\n",
    "\n",
    "# Intersection\n",
    "kgraph3 = kgraph1 & kgraph2 # kgraph1.intersection(kgraph2)\n",
    "\n",
    "# Difference\n",
    "kgraph3 = kgraph1 - kgraph2 # kgraph1.difference(kgraph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgraph3.to_jsonl(\"results/sample_graph3.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./comet-bart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': ['sentence_extractor',\n",
       "  'noun_phrase_extractor',\n",
       "  'verb_phrase_extractor'],\n",
       " 'relation': ['simple_relation_matcher', 'graph_relation_matcher']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.remove_processor(\"noun_phrase_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': ['sentence_extractor', 'verb_phrase_extractor'],\n",
       " 'relation': ['simple_relation_matcher', 'graph_relation_matcher']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Head Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from spacy.tokens import Doc\n",
    "import spacy\n",
    "\n",
    "from kogito.core.processors.head import KnowledgeHeadExtractor, KnowledgeHead\n",
    "\n",
    "class AdjectiveHeadExtractor(KnowledgeHeadExtractor):\n",
    "   def extract(self, text: str, doc: Optional[Doc] = None) -> List[KnowledgeHead]:\n",
    "      if not doc:\n",
    "            doc = self.lang(text)\n",
    "\n",
    "      heads = []\n",
    "\n",
    "      for token in doc:\n",
    "            if token.pos_ == \"ADJ\":\n",
    "               heads.append(KnowledgeHead(text=token.text, entity=token))\n",
    "\n",
    "      return heads\n",
    "\n",
    "adj_extractor = AdjectiveHeadExtractor(\"adj_extractor\", spacy.load(\"en_core_web_sm\"))\n",
    "csi.add_processor(adj_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': ['sentence_extractor', 'verb_phrase_extractor', 'adj_extractor'],\n",
       " 'relation': ['simple_relation_matcher', 'graph_relation_matcher']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "csi = CommonsenseInference()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Relation Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from kogito.core.processors.head import KnowledgeHead\n",
    "from kogito.core.processors.relation import KnowledgeRelationMatcher\n",
    "from kogito.core.relation import KnowledgeRelation, X_NEED, CAUSES\n",
    "\n",
    "class ConstantRelationMatcher(KnowledgeRelationMatcher):\n",
    "   def match(\n",
    "      self, heads: List[KnowledgeHead], relations: List[KnowledgeRelation] = None, **kwargs\n",
    "   ) -> List[Tuple[KnowledgeHead, KnowledgeRelation]]:\n",
    "      head_relations = []\n",
    "\n",
    "      for head in heads:\n",
    "            head_relations.append((head, X_NEED))\n",
    "            head_relations.append((head, CAUSES))\n",
    "\n",
    "      return head_relations\n",
    "\n",
    "const_rel_matcher = ConstantRelationMatcher(\"const_rel_matcher\", spacy.load(\"en_core_web_sm\"))\n",
    "csi.add_processor(const_rel_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': ['sentence_extractor',\n",
       "  'noun_phrase_extractor',\n",
       "  'verb_phrase_extractor'],\n",
       " 'relation': ['simple_relation_matcher',\n",
       "  'graph_relation_matcher',\n",
       "  'const_rel_matcher']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n",
      "Matching knowledge heads with relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True)\n",
    "kgraph.to_jsonl(\"results/kgraph_dry_run.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"I wanted to feed him. he didnt listen to me\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True)\n",
    "kgraph.to_jsonl(\"results/kgraph_dry_run_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n",
      "Matching knowledge heads with relations...\n"
     ]
    }
   ],
   "source": [
    "from kogito.core.relation import OBJECT_USE, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, relations=[OBJECT_USE, CAUSES])\n",
    "kgraph.to_jsonl(\"results/kgraph_rel_subset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Head extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching knowledge heads with relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, extract_heads=False)\n",
    "kgraph.to_jsonl(\"results/kgraph_no_head_extract.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Relation matching and no subset of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, match_relations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Relation matching with subset of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n"
     ]
    }
   ],
   "source": [
    "from kogito.core.relation import DESIRES, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, match_relations=False, relations=[CAUSES, DESIRES])\n",
    "kgraph.to_jsonl(\"results/kgraph_no_match_subset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Head extraction, no Relation matching with subset of relations (hence, ultimate manual specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.relation import DESIRES, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, extract_heads=False, match_relations=False, relations=[CAUSES, DESIRES])\n",
    "kgraph.to_jsonl(\"results/kgraph_manual.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching knowledge heads with relations...\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"post office\", \"to get out of the room\"], dry_run=True)\n",
    "kgraph.to_jsonl(\"results/kgraph_manual_heads.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation matching (SWEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 204/204 [00:00<00:00, 84.9kB/s]\n",
      "Downloading: 100%|██████████| 160M/160M [00:10<00:00, 15.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching knowledge heads with relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/mismayil/opt/anaconda3/envs/kogito-test/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 191.39it/s]\n",
      "Took 0.8768618106842041 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/opt/anaconda3/envs/kogito-test/lib/python3.8/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import SWEMRelationMatcher\n",
    "from kogito.models.bart.comet import COMETBART\n",
    "from kogito.core.model import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "swem_matcher = SWEMRelationMatcher(\"swem_relation_matcher\")\n",
    "csi.add_processor(swem_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_modelbased_relations_swem.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation matching (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 235/235 [00:00<00:00, 63.7kB/s]\n",
      "Downloading: 100%|██████████| 265M/265M [00:16<00:00, 16.4MB/s] \n",
      "Downloading: 100%|██████████| 483/483 [00:00<00:00, 226kB/s]\n",
      "Downloading: 100%|██████████| 268M/268M [00:15<00:00, 17.1MB/s] \n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching knowledge heads with relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 232k/232k [00:00<00:00, 700kB/s] \n",
      "Downloading: 100%|██████████| 28.0/28.0 [00:00<00:00, 15.2kB/s]\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s]\n",
      "Took 3.6173558235168457 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import DistilBERTRelationMatcher\n",
    "from kogito.core.model import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "dbert_matcher = DistilBERTRelationMatcher(\"dbert_relation_matcher\")\n",
    "csi.add_processor(dbert_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_modelbased_relations_dbert.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation Matching (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching knowledge heads with relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "Took 2.3340957164764404 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import BERTRelationMatcher\n",
    "from kogito.core.model import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "bert_matcher = BERTRelationMatcher(\"dbert_relation_matcher\")\n",
    "csi.add_processor(bert_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_modelbased_relations_bert.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3 Based Commonsense Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching knowledge heads with relations...\n",
      "Generating knowledge graph...\n",
      "Took 1.2147226333618164 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3.zeroshot import GPT3Zeroshot\n",
    "import time, os\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "model = GPT3Zeroshot(api_key=\"\", model_name=\"text-davinci-002\")\n",
    "sample_graph = KnowledgeGraph.from_csv(\"sample_graph.tsv\", sep=\"\\t\", header=None)\n",
    "heads = [\"PersonX accuses PersonY of cheating\", \"PersonX aces PersonX's exam\"]\n",
    "\n",
    "start = time.time()\n",
    "kgraph = csi.infer(model=model, heads=heads, sample_graph=sample_graph, model_args={\"debug\": True})\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_gpt3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3 Based Commonsense Inference with custom relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching knowledge heads with relations...\n",
      "Generating knowledge graph...\n",
      "Took 1.7802231311798096 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3.zeroshot import GPT3Zeroshot\n",
    "from kogito.core.relation import KnowledgeRelation, register_relation\n",
    "import time, os\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "def x_wishes_verbalizer(head, **kwargs):\n",
    "   # index will be passed from the model\n",
    "   # so that we can enumerate samples which helps with inference\n",
    "   index = kwargs.get(\"index\")\n",
    "   index_txt = f\"{index}\" if index is not None else \"\"\n",
    "   return f\"Situation {index_txt}: {head}\\nWishes: As a result, PersonX wishes\"\n",
    "\n",
    "X_WISHES = KnowledgeRelation(\"xWishes\",\n",
    "                             verbalizer=x_wishes_verbalizer,\n",
    "                             prompt=\"How does this situation affect each character's wishes?\")\n",
    "register_relation(X_WISHES)\n",
    "\n",
    "model = GPT3Zeroshot(api_key=\"\", model_name=\"text-davinci-002\")\n",
    "\n",
    "sample_graph = KnowledgeGraph.from_csv(\"sample_graph2.tsv\", sep=\"\\t\", header=None)\n",
    "\n",
    "heads = [\"PersonX makes a huge mistake\", \"PersonX sees PersonY's point\"]\n",
    "\n",
    "start = time.time()\n",
    "kgraph = csi.infer(model=model,\n",
    "                   heads=heads,\n",
    "                   sample_graph=sample_graph,\n",
    "                   model_args={\"debug\": True, \"top_p\": 0.5, \"stop\": \"\\n\"})\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_gpt3_custom_relation.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonsense Knowledge Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 2.46M/2.46M [00:00<00:00, 4.11MB/s]\n",
      "Downloading: 100%|██████████| 56.0/56.0 [00:00<00:00, 18.7kB/s]\n",
      "Downloading: 100%|██████████| 165/165 [00:00<00:00, 60.0kB/s]\n",
      "Downloading: 100%|██████████| 285/285 [00:00<00:00, 115kB/s]\n",
      "Downloading: 100%|██████████| 854/854 [00:00<00:00, 285kB/s]\n",
      "Downloading: 100%|██████████| 1.74G/1.74G [02:24<00:00, 12.0MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00024847043096087873], [6.804546865168959e-05], [0.9954416751861572]]\n",
      "Knowledge(head=\"drive\", relation=\"HasSubEvent\", tails=['get into car'])\n"
     ]
    }
   ],
   "source": [
    "from kogito.linkers.deberta import DebertaLinker\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "linker = DebertaLinker()\n",
    "context = [\n",
    "      \"joey was pretending to drive his wife to work .\",\n",
    "      \"the truth was that he was taking her on a trip .\",\n",
    "      \"when they passed the road for her workplace , she asked what was up .\",\n",
    "      \"that 's when he announced the trip detour plans .\",\n",
    "      \"his wife was so thrilled and they really enjoyed their trip together .\"\n",
    "    ]\n",
    "input_graph = KnowledgeGraph.from_csv(\"sample_linking_graph.csv\", sep=\"|\", header=None)\n",
    "relevance_probs = linker.link(input_graph, context)\n",
    "print(relevance_probs)\n",
    "\n",
    "filtered_graph = linker.filter(input_graph, context)\n",
    "\n",
    "print(filtered_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonsense Inference with Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n",
      "Matching knowledge heads with relations...\n",
      "Generating knowledge graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:12<00:00, 12.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n",
      "Matching knowledge heads with relations...\n",
      "Generating knowledge graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default Deberta linker for filtering...\n",
      "Filtering knowledge graph based on the context...\n"
     ]
    }
   ],
   "source": [
    "from kogito.models.bart.comet import COMETBART\n",
    "from kogito.inference import CommonsenseInference\n",
    "\n",
    "model = COMETBART.from_pretrained()\n",
    "csi = CommonsenseInference()\n",
    "\n",
    "text = \"PersonX wraps gifts\"\n",
    "kgraph = csi.infer(text, model)\n",
    "\n",
    "kgraph.to_jsonl(\"kgraph_without_context.json\")\n",
    "\n",
    "context = ['hank had to wrap a lot of gifts for his family .', \n",
    "           'he ran out of wrapping paper with 4 gifts to go .',\n",
    "           'he went to the kitchen and found shopping bags .', \n",
    "           'he cut up the bags to make sheets of paper .', \n",
    "           'he used the paper to wrap the last of the gifts .']\n",
    "\n",
    "kgraph2 = csi.infer(text, model, context=context)\n",
    "kgraph2.to_jsonl(\"kgraph_with_context.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78e267dbbd536cf72b9151fa10598d02f0742e0d77c5a78f8f9ba9a5d38a282d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
