{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n",
      "Generating commonsense graph...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.97s/it]\n"
     ]
    }
   ],
   "source": [
    "from kogito.models.bart.comet import COMETBART\n",
    "from kogito.inference import CommonsenseInference\n",
    "\n",
    "# Load pre-trained model from HuggingFace\n",
    "model = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "\n",
    "# Initialize inference module with a spacy language pipeline\n",
    "csi = CommonsenseInference(language=\"en_core_web_sm\")\n",
    "\n",
    "# Run inference\n",
    "text = \"PersonX becomes a great basketball player\"\n",
    "kgraph = csi.infer(text, model)\n",
    "\n",
    "# Save output knowledge graph to JSON file\n",
    "kgraph.to_jsonl(\"kgraph.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.head import KnowledgeHead\n",
    "from kogito.core.knowledge import Knowledge\n",
    "from kogito.core.relation import X_NEED\n",
    "\n",
    "head = KnowledgeHead(\"PersonX buys lunch\")\n",
    "knowledge = Knowledge(head=head, relation=X_NEED, tails=[\"bring a wallet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.knowledge import Knowledge, KnowledgeGraph\n",
    "from kogito.core.head import KnowledgeHead\n",
    "from kogito.core.relation import X_NEED, CAUSES\n",
    "\n",
    "knowledge1 = Knowledge(head=KnowledgeHead(\"PersonX buys lunch\"), relation=X_NEED, tails=[\"bring a wallet\"])\n",
    "knowledge2 = Knowledge(head=KnowledgeHead(\"Throwing a party\"), relation=CAUSES, tails=[\"have fun\"])\n",
    "\n",
    "kgraph = KnowledgeGraph([knowledge1, knowledge2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge(head=\"PersonX buys lunch\", relation=\"xNeed\", tails=['bring a wallet'])\n",
      "Knowledge(head=\"Throwing a party\", relation=\"Causes\", tails=['have fun'])\n"
     ]
    }
   ],
   "source": [
    "for knowledge in kgraph:\n",
    "    print(knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From csv\n",
    "kgraph1 = KnowledgeGraph.from_csv(\"sample_graph.tsv\", sep=\"\\t\", header=None)\n",
    "\n",
    "# From jsonl (list of json objects)\n",
    "kgraph2 = KnowledgeGraph.from_jsonl(\"sample_graph.jsonl\", head_attr=\"source\", relation_attr=\"rel\", tails_attr=\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union\n",
    "kgraph3 = kgraph1 + kgraph2 # kgraph1.union(kgraph2)\n",
    "\n",
    "# Intersection\n",
    "kgraph3 = kgraph1 & kgraph2 # kgraph1.intersection(kgraph2)\n",
    "\n",
    "# Difference\n",
    "kgraph3 = kgraph1 - kgraph2 # kgraph1.difference(kgraph2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kgraph3.to_jsonl(\"sample_graph3.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./comet-bart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.remove_processor(\"noun_phrase_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Head Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from spacy.tokens import Doc\n",
    "import spacy\n",
    "\n",
    "from kogito.core.processors.head import KnowledgeHeadExtractor, KnowledgeHead\n",
    "\n",
    "class AdjectiveHeadExtractor(KnowledgeHeadExtractor):\n",
    "   def extract(self, text: str, doc: Optional[Doc] = None) -> List[KnowledgeHead]:\n",
    "      if not doc:\n",
    "            doc = self.lang(text)\n",
    "\n",
    "      heads = []\n",
    "\n",
    "      for token in doc:\n",
    "            if token.pos_ == \"ADJ\":\n",
    "               heads.append(KnowledgeHead(text=token.text, entity=token))\n",
    "\n",
    "      return heads\n",
    "\n",
    "adj_extractor = AdjectiveHeadExtractor(\"adj_extractor\", spacy.load(\"en_core_web_sm\"))\n",
    "csi.add_processor(adj_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': ['sentence_extractor',\n",
       "  'noun_phrase_extractor',\n",
       "  'verb_phrase_extractor',\n",
       "  'adj_extractor'],\n",
       " 'relation': ['simple_relation_matcher', 'graph_relation_matcher']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "csi = CommonsenseInference()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Relation Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from kogito.core.processors.head import KnowledgeHead\n",
    "from kogito.core.processors.relation import KnowledgeRelationMatcher\n",
    "from kogito.core.relation import KnowledgeRelation, X_NEED, CAUSES\n",
    "\n",
    "class ConstantRelationMatcher(KnowledgeRelationMatcher):\n",
    "   def match(\n",
    "      self, heads: List[KnowledgeHead], relations: List[KnowledgeRelation] = None, **kwargs\n",
    "   ) -> List[Tuple[KnowledgeHead, KnowledgeRelation]]:\n",
    "      head_relations = []\n",
    "\n",
    "      for head in heads:\n",
    "            head_relations.append((head, X_NEED))\n",
    "            head_relations.append((head, CAUSES))\n",
    "\n",
    "      return head_relations\n",
    "\n",
    "const_rel_matcher = ConstantRelationMatcher(\"const_rel_matcher\", spacy.load(\"en_core_web_sm\"))\n",
    "csi.add_processor(const_rel_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': ['sentence_extractor',\n",
       "  'noun_phrase_extractor',\n",
       "  'verb_phrase_extractor',\n",
       "  'adj_extractor'],\n",
       " 'relation': ['simple_relation_matcher',\n",
       "  'graph_relation_matcher',\n",
       "  'const_rel_matcher']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csi.processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True)\n",
    "kgraph.to_jsonl(\"results/kgraph_dry_run.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"I wanted to feed him. he didnt listen to me\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True)\n",
    "kgraph.to_jsonl(\"results/kgraph_dry_run_2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n",
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from kogito.core.relation import OBJECT_USE, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, relations=[OBJECT_USE, CAUSES])\n",
    "kgraph.to_jsonl(\"results/kgraph_rel_subset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Head extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, extract_heads=False)\n",
    "kgraph.to_jsonl(\"results/kgraph_no_head_extract.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Relation matching and no subset of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No relation found to match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mismayil/Desktop/EPFL/nlplab/kogito/examples/demo.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mismayil/Desktop/EPFL/nlplab/kogito/examples/demo.ipynb#ch0000020?line=0'>1</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGabby always brought cookies to school.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mismayil/Desktop/EPFL/nlplab/kogito/examples/demo.ipynb#ch0000020?line=1'>2</a>\u001b[0m kgraph: KnowledgeGraph \u001b[39m=\u001b[39m csi\u001b[39m.\u001b[39;49minfer(text, dry_run\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, match_relations\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/temp/lib/python3.8/site-packages/kogito/inference.py:155\u001b[0m, in \u001b[0;36mCommonsenseInference.infer\u001b[0;34m(self, text, model, heads, model_args, extract_heads, match_relations, relations, dry_run, sample_graph)\u001b[0m\n\u001b[1;32m    151\u001b[0m     head_relations \u001b[39m=\u001b[39m head_relations\u001b[39m.\u001b[39munion(\n\u001b[1;32m    152\u001b[0m         \u001b[39mset\u001b[39m(\u001b[39mlist\u001b[39m(product(kg_heads, relations)))\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo relation found to match\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m kg_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m head_relation \u001b[39min\u001b[39;00m head_relations:\n",
      "\u001b[0;31mValueError\u001b[0m: No relation found to match"
     ]
    }
   ],
   "source": [
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, match_relations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Relation matching with subset of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting heads...\n"
     ]
    }
   ],
   "source": [
    "from kogito.core.relation import DESIRES, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, match_relations=False, relations=[CAUSES, DESIRES])\n",
    "kgraph.to_jsonl(\"results/kgraph_no_match_subset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Head extraction, no Relation matching with subset of relations (hence, ultimate manual specification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.relation import DESIRES, CAUSES\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(text, dry_run=True, extract_heads=False, match_relations=False, relations=[CAUSES, DESIRES])\n",
    "kgraph.to_jsonl(\"results/kgraph_manual.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "text = \"Gabby always brought cookies to school.\"\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"post office\", \"to get out of the room\"], dry_run=True)\n",
    "kgraph.to_jsonl(\"results/kgraph_manual_heads.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation matching (SWEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/opt/anaconda3/envs/temp/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/mismayil/opt/anaconda3/envs/temp/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 173.23it/s]\n",
      "Took 0.6309409141540527 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/opt/anaconda3/envs/temp/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import SWEMRelationMatcher\n",
    "from kogito.models.bart.comet import COMETBART\n",
    "from kogito.core.model import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "swem_matcher = SWEMRelationMatcher(\"swem_relation_matcher\")\n",
    "csi.add_processor(swem_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_modelbased_relations_swem.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation matching (DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  6.80it/s]\n",
      "Took 2.5445749759674072 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import DistilBERTRelationMatcher\n",
    "from kogito.core.model import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "dbert_matcher = DistilBERTRelationMatcher(\"dbert_relation_matcher\")\n",
    "csi.add_processor(dbert_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_modelbased_relations_dbert.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model based Relation Matching (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]\n",
      "Took 2.6959590911865234 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.core.processors.relation import BERTRelationMatcher\n",
    "from kogito.core.model import KnowledgeModel\n",
    "import time\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "bert_matcher = BERTRelationMatcher(\"dbert_relation_matcher\")\n",
    "csi.add_processor(bert_matcher)\n",
    "start = time.time()\n",
    "# model: KnowledgeModel = COMETBART.from_pretrained(\"mismayil/comet-bart-ai2\")\n",
    "kgraph: KnowledgeGraph = csi.infer(heads=[\"banana\", \"love another\", \"Student gets a card\"], dry_run=True)\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_modelbased_relations_bert.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3 Based Commonsense Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n",
      "Generating commonsense graph...\n",
      "Took 3.8873648643493652 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3.zeroshot import GPT3Zeroshot\n",
    "import time, os\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "model = GPT3Zeroshot(api_key=\"\", model_name=\"text-davinci-002\")\n",
    "sample_graph = KnowledgeGraph.from_csv(\"sample_graph.tsv\", sep=\"\\t\", header=None)\n",
    "heads = [\"PersonX accuses PersonY of cheating\", \"PersonX aces PersonX's exam\"]\n",
    "\n",
    "start = time.time()\n",
    "kgraph = csi.infer(model=model, heads=heads, sample_graph=sample_graph, model_args={\"debug\": True})\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_gpt3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3 Based Commonsense Inference with custom relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching relations...\n",
      "Generating commonsense graph...\n",
      "Took 3.2485480308532715 seconds\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3.zeroshot import GPT3Zeroshot\n",
    "from kogito.core.relation import KnowledgeRelation, register_relation\n",
    "import time, os\n",
    "\n",
    "csi = CommonsenseInference()\n",
    "csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "def x_wishes_verbalizer(head, **kwargs):\n",
    "   # index will be passed from the model\n",
    "   # so that we can enumerate samples which helps with inference\n",
    "   index = kwargs.get(\"index\")\n",
    "   index_txt = f\"{index}\" if index is not None else \"\"\n",
    "   return f\"Situation {index_txt}: {head}\\nWishes: As a result, PersonX wishes\"\n",
    "\n",
    "X_WISHES = KnowledgeRelation(\"xWishes\",\n",
    "                             verbalizer=x_wishes_verbalizer,\n",
    "                             prompt=\"How does this situation affect each character's wishes?\")\n",
    "register_relation(X_WISHES)\n",
    "\n",
    "model = GPT3Zeroshot(api_key=\"\", model_name=\"text-davinci-002\")\n",
    "\n",
    "sample_graph = KnowledgeGraph.from_csv(\"sample_graph2.tsv\", sep=\"\\t\", header=None)\n",
    "\n",
    "heads = [\"PersonX makes a huge mistake\", \"PersonX sees PersonY's point\"]\n",
    "\n",
    "start = time.time()\n",
    "kgraph = csi.infer(model=model,\n",
    "                   heads=heads,\n",
    "                   sample_graph=sample_graph,\n",
    "                   model_args={\"debug\": True, \"top_p\": 0.5, \"stop\": \"\\n\"})\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Took {end-start} seconds\")\n",
    "kgraph.to_jsonl(\"results/kgraph_gpt3_custom_relation.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commonsense Knowledge Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0002484701981302351, 6.804546865168959e-05, 0.9954416751861572]\n",
      "Knowledge(head=\"drive\", relation=\"HasSubEvent\", tails=[' get into car'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n",
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"
     ]
    }
   ],
   "source": [
    "from kogito.linkers.deberta import DebertaLinker\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "\n",
    "linker = DebertaLinker(\"../ComFact_DeBERTa/deberta-large-nlu-fact_full/checkpoint-236560\")\n",
    "context = [\n",
    "      \"joey was pretending to drive his wife to work .\",\n",
    "      \"the truth was that he was taking her on a trip .\",\n",
    "      \"when they passed the road for her workplace , she asked what was up .\",\n",
    "      \"that 's when he announced the trip detour plans .\",\n",
    "      \"his wife was so thrilled and they really enjoyed their trip together .\"\n",
    "    ]\n",
    "input_graph = KnowledgeGraph.from_csv(\"sample_linking_graph.csv\", sep=\"|\", header=None)\n",
    "relevance_probs = linker.link(input_graph, context)\n",
    "print(relevance_probs)\n",
    "\n",
    "filtered_graph = linker.filter(input_graph, context)\n",
    "\n",
    "print(filtered_graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e80d669f60bd34413df3f847d16a09f3fef6827513c4f925b04d67ca5f47b92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
