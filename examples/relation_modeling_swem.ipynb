{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def create_emb_matrix(embedding_dim=100):\n",
    "    glove = pd.read_csv(f'data/glove/glove.6B.{embedding_dim}d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "    vocab = {'<pad>': 0, '<unk>': 1}\n",
    "    embeddings = np.zeros((len(glove) + 2, embedding_dim))\n",
    "    embeddings[0] = np.zeros(embedding_dim)\n",
    "    embeddings[1] = np.zeros(embedding_dim)\n",
    "\n",
    "    for index, (key, val) in tqdm(enumerate(glove.T.items())):\n",
    "        vocab[key] = index + 2\n",
    "        embeddings[index+2] = val.to_numpy()\n",
    "\n",
    "    return vocab, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, emb_matrix = create_emb_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.relation import PHYSICAL_RELATIONS, SOCIAL_RELATIONS, EVENT_RELATIONS\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torchtext.vocab import GloVe\n",
    "import wandb\n",
    "import spacy\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def load_data(datapath):\n",
    "    data = []\n",
    "    head_label_set = set()\n",
    "\n",
    "    with open(datapath) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                head, relation, _ = line.split('\\t')\n",
    "\n",
    "                label = 0 \n",
    "\n",
    "                if relation in EVENT_RELATIONS:\n",
    "                    label = 1\n",
    "                elif relation in SOCIAL_RELATIONS:\n",
    "                    label = 2\n",
    "\n",
    "                if (head, label) not in head_label_set:\n",
    "                    data.append((head, label))\n",
    "                    head_label_set.add((head, label))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return pd.DataFrame(data, columns=['text', 'label'])\n",
    "    \n",
    "\n",
    "class HeadDataset(Dataset):\n",
    "    def __init__(self, df, vocab):\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.labels = df['label'].to_numpy()\n",
    "        self.texts = pad_sequence([torch.tensor([vocab.get(token.text, 1) for token in nlp(text)], dtype=torch.int) for text in df['text']], batch_first=True)\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "\n",
    "class MaxPool(nn.Module):\n",
    "    def forward(self, X):\n",
    "        values, _ = torch.max(X, dim=1)\n",
    "        return values\n",
    "\n",
    "\n",
    "class AvgPool(nn.Module):\n",
    "    def forward(self, X):\n",
    "        return torch.mean(X, dim=1)\n",
    "\n",
    "\n",
    "class SWEMClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim=100, num_classes=3, pooling=\"max\", embedding_matrix=None):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=embedding_matrix.shape[0],\n",
    "                                      embedding_dim=embedding_matrix.shape[1]).from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n",
    "        self.pool = MaxPool() if pooling == \"max\" else AvgPool()\n",
    "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        outputs = self.embedding(X)\n",
    "        outputs = self.pool(outputs)\n",
    "        outputs = self.linear(outputs)\n",
    "        outputs = self.softmax(outputs)\n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    def save_pretrained(self, path):\n",
    "        torch.save(self, path)\n",
    "\n",
    "\n",
    "def train(model, train_dataset, val_dataset, learning_rate=1e-3, epochs=10, batch_size=8):\n",
    "    # wandb.init(project=\"kogito-relation-matcher\", config={\"learning_rate\": learning_rate, \"epochs\": epochs, \"batch_size\": batch_size})\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        print(\"Using CUDA\")\n",
    "        model = model.to(device)\n",
    "        criterion = criterion.to(device)\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            model.zero_grad()\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            X = train_input.to(device)\n",
    "\n",
    "            output = model(X)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                X = val_input.to(device)\n",
    "\n",
    "                output = model(X)\n",
    "\n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "        \n",
    "        train_loss = total_loss_train / len(train_data)\n",
    "        train_acc = total_acc_train / len(train_data)\n",
    "        val_loss = total_loss_val / len(val_data)\n",
    "        val_acc = total_acc_val / len(val_data)\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Train Loss: {train_loss: .3f} \\\n",
    "            | Train Accuracy: {train_acc: .3f} \\\n",
    "            | Val Loss: {val_loss: .3f} \\\n",
    "            | Val Accuracy: {val_acc: .3f}')\n",
    "        \n",
    "        # wandb.log({\"train_loss\": train_loss, \"train_accuracy\": train_acc, \"val_loss\": val_loss, \"val_accuracy\": val_acc})\n",
    "        # model.save_pretrained(f\"./models/checkpoint_{epoch_num}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 580.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.014             | Train Accuracy:  0.563             | Val Loss:  0.014             | Val Accuracy:  0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 574.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.013             | Train Accuracy:  0.594             | Val Loss:  0.014             | Val Accuracy:  0.502\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data(\"data/atomic2020_data-feb2021/train.tsv\")\n",
    "dev_df = load_data(\"data/atomic2020_data-feb2021/dev.tsv\")\n",
    "train_data = HeadDataset(train_df, vocab=vocab)\n",
    "val_data = HeadDataset(dev_df, vocab=vocab)\n",
    "# model.save_pretrained(\"./models/final_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 442.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.014             | Train Accuracy:  0.565             | Val Loss:  0.014             | Val Accuracy:  0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 659.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.013             | Train Accuracy:  0.592             | Val Loss:  0.014             | Val Accuracy:  0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 634.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.012             | Train Accuracy:  0.598             | Val Loss:  0.014             | Val Accuracy:  0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 604.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.012             | Train Accuracy:  0.598             | Val Loss:  0.013             | Val Accuracy:  0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 679.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.012             | Train Accuracy:  0.600             | Val Loss:  0.013             | Val Accuracy:  0.510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 695.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 | Train Loss:  0.012             | Train Accuracy:  0.602             | Val Loss:  0.013             | Val Accuracy:  0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 544.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 | Train Loss:  0.012             | Train Accuracy:  0.602             | Val Loss:  0.013             | Val Accuracy:  0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 692.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 | Train Loss:  0.012             | Train Accuracy:  0.603             | Val Loss:  0.013             | Val Accuracy:  0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 626.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 | Train Loss:  0.012             | Train Accuracy:  0.602             | Val Loss:  0.013             | Val Accuracy:  0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 583.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 | Train Loss:  0.012             | Train Accuracy:  0.603             | Val Loss:  0.013             | Val Accuracy:  0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 659.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 | Train Loss:  0.012             | Train Accuracy:  0.603             | Val Loss:  0.013             | Val Accuracy:  0.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 664.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 | Train Loss:  0.012             | Train Accuracy:  0.604             | Val Loss:  0.013             | Val Accuracy:  0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 689.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 13 | Train Loss:  0.012             | Train Accuracy:  0.604             | Val Loss:  0.013             | Val Accuracy:  0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 667.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 14 | Train Loss:  0.012             | Train Accuracy:  0.604             | Val Loss:  0.013             | Val Accuracy:  0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 753.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 15 | Train Loss:  0.012             | Train Accuracy:  0.603             | Val Loss:  0.013             | Val Accuracy:  0.510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 701.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 16 | Train Loss:  0.012             | Train Accuracy:  0.603             | Val Loss:  0.013             | Val Accuracy:  0.510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 702.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 17 | Train Loss:  0.012             | Train Accuracy:  0.604             | Val Loss:  0.013             | Val Accuracy:  0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 643.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 18 | Train Loss:  0.012             | Train Accuracy:  0.605             | Val Loss:  0.013             | Val Accuracy:  0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 648.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 19 | Train Loss:  0.012             | Train Accuracy:  0.604             | Val Loss:  0.013             | Val Accuracy:  0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843/843 [00:01<00:00, 585.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20 | Train Loss:  0.012             | Train Accuracy:  0.603             | Val Loss:  0.013             | Val Accuracy:  0.509\n"
     ]
    }
   ],
   "source": [
    "model = SWEMClassifier(embedding_matrix=emb_matrix)\n",
    "train(model=model, train_dataset=train_data, val_dataset=val_data, epochs=20, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
