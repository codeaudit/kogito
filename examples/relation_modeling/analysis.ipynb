{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import load_data\n",
    "\n",
    "train_df = load_data(\"data/atomic2020_data-feb2021/train.tsv\", multi_label=True)\n",
    "val_df = load_data(\"data/atomic2020_data-feb2021/dev.tsv\", multi_label=True)\n",
    "test_df = load_data(\"data/atomic2020_data-feb2021/test.tsv\", multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36940, 2962, 6569)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abolishes ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abolishes ___ in the states</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abolishes the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text      label\n",
       "0       PersonX abandons ___ altogether  [0, 0, 1]\n",
       "1   PersonX abandons the ___ altogether  [0, 1, 1]\n",
       "2      PersonX abolishes ___ altogether  [0, 1, 1]\n",
       "3   PersonX abolishes ___ in the states  [0, 1, 1]\n",
       "4  PersonX abolishes the ___ altogether  [0, 1, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_labels(df):\n",
    "    df['label_0'] = df.label.apply(lambda l: l[0])\n",
    "    df['label_1'] = df.label.apply(lambda l: l[1])\n",
    "    df['label_2'] = df.label.apply(lambda l: l[2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = explode_labels(train_df), explode_labels(val_df), explode_labels(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    22457\n",
       " 1    14483\n",
       " Name: label_0, dtype: int64,\n",
       " 0    18538\n",
       " 1    18402\n",
       " Name: label_1, dtype: int64,\n",
       " 1    21006\n",
       " 0    15934\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label_0.value_counts(), train_df.label_1.value_counts(), train_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    2630\n",
       " 1     332\n",
       " Name: label_0, dtype: int64,\n",
       " 1    2263\n",
       " 0     699\n",
       " Name: label_1, dtype: int64,\n",
       " 1    2228\n",
       " 0     734\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.label_0.value_counts(), val_df.label_1.value_counts(), val_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    4668\n",
       " 1    1901\n",
       " Name: label_0, dtype: int64,\n",
       " 1    4419\n",
       " 0    2150\n",
       " Name: label_1, dtype: int64,\n",
       " 0    3996\n",
       " 1    2573\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label_0.value_counts(), test_df.label_1.value_counts(), test_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140049/140049 [00:00<00:00, 894739.45it/s] \n",
      "100%|██████████| 14524/14524 [00:00<00:00, 1082910.93it/s]\n",
      "100%|██████████| 27270/27270 [00:00<00:00, 1091368.28it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "\n",
    "def create_vocab(data):\n",
    "    vocab = set()\n",
    "    text = \" \".join(data.text.to_list())\n",
    "    doc = nlp(text)\n",
    "    for token in tqdm(doc, total=len(doc)):\n",
    "        vocab.add(token.text.lower())\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "train_vocab, val_vocab, test_vocab = create_vocab(train_df), create_vocab(val_df), create_vocab(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15235929505400797, 0.8725581395348837)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(val_vocab)) / len(train_vocab), len(train_vocab.intersection(val_vocab)) / len(val_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27109559002680095, 0.8000958772770853)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(test_vocab)) / len(train_vocab), len(train_vocab.intersection(test_vocab)) / len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "atomic_df = pd.read_csv(\"data/atomic/v4_atomic_all_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>oEffect</th>\n",
       "      <th>oReact</th>\n",
       "      <th>oWant</th>\n",
       "      <th>xAttr</th>\n",
       "      <th>xEffect</th>\n",
       "      <th>xIntent</th>\n",
       "      <th>xNeed</th>\n",
       "      <th>xReact</th>\n",
       "      <th>xWant</th>\n",
       "      <th>prefix</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX 'd better go</td>\n",
       "      <td>[\"none\", \"none\"]</td>\n",
       "      <td>[\"none\", \"none\"]</td>\n",
       "      <td>[\"none\", \"none\", \"none\"]</td>\n",
       "      <td>[\"avoidant\", \"weak\", \"hurried\", \"late\", \"Tardy...</td>\n",
       "      <td>[\"She ran to the bathroom\", \"She finally made ...</td>\n",
       "      <td>[\"to go somewhere else more important.\", \"none\"]</td>\n",
       "      <td>[\"none\", \"none\", \"none\"]</td>\n",
       "      <td>[\"the person feels happy since he arrived at h...</td>\n",
       "      <td>[\"to escape from him\", \"to resign his job\", \"t...</td>\n",
       "      <td>[\"better\", \"go\"]</td>\n",
       "      <td>dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[\"none\", \"none\"]</td>\n",
       "      <td>[\"dejected\"]</td>\n",
       "      <td>[\"none\", \"none\", \"to find a new job for him\", ...</td>\n",
       "      <td>[\"impatient\", \"decisive\", \"undependable\", \"fic...</td>\n",
       "      <td>[\"gets a reputation as a quitter\", \"hangs head...</td>\n",
       "      <td>[\"put a stop\"]</td>\n",
       "      <td>[\"Plows the field.\", \"Gets exhausted from it.\"...</td>\n",
       "      <td>[\"authoritative\"]</td>\n",
       "      <td>[\"Sell his land.\", \"Was just city.\", \"to start...</td>\n",
       "      <td>[\"abandons\", \"altogether\"]</td>\n",
       "      <td>trn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abandons the ___ altogether</td>\n",
       "      <td>[\"none\", \"none\", \"none\"]</td>\n",
       "      <td>[\"defeat\"]</td>\n",
       "      <td>[\"none\", \"to do something else as well\", \"they...</td>\n",
       "      <td>[\"flaky\", \"irresponsible\", \"desperate\", \"convi...</td>\n",
       "      <td>[\"eats all the cakes\", \"abandons his diets too...</td>\n",
       "      <td>[\"to appear not interested\"]</td>\n",
       "      <td>[\"none\", \"to get frustrated\", \"to determine it...</td>\n",
       "      <td>[\"pressurized\"]</td>\n",
       "      <td>[\"to go out\", \"to find other place\", \"find som...</td>\n",
       "      <td>[\"abandons\", \"altogether\"]</td>\n",
       "      <td>trn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abolishes ___ altogether</td>\n",
       "      <td>[\"none\", \"none\", \"none\"]</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[\"to be free\", \"to do things of their own wish...</td>\n",
       "      <td>[\"ruthless\", \"destructive\", \"strict\", \"determi...</td>\n",
       "      <td>[\"loss money\", \"change house\", \"get loan\", \"pe...</td>\n",
       "      <td>[\"give a punishment in person\"]</td>\n",
       "      <td>[\"to have a plan\", \"to have a reason\", \"to kno...</td>\n",
       "      <td>[\"he was sad\"]</td>\n",
       "      <td>[\"human to be free\", \"not to feel pain\", \"to m...</td>\n",
       "      <td>[\"abolishes\", \"altogether\"]</td>\n",
       "      <td>trn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abolishes ___ in the states</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[\"to celebrate\", \"to write about the new law\",...</td>\n",
       "      <td>[\"bold\", \"authoritative\", \"determined\", \"heroi...</td>\n",
       "      <td>[\"none\"]</td>\n",
       "      <td>[\"this is unhappiness for people\"]</td>\n",
       "      <td>[\"to find a problem\", \"to find out to stop tha...</td>\n",
       "      <td>[\"sad\"]</td>\n",
       "      <td>[\"to enforce the ruling\", \"memorialize the law...</td>\n",
       "      <td>[\"abolishes\", \"states\"]</td>\n",
       "      <td>trn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 event                   oEffect  \\\n",
       "0                 PersonX 'd better go          [\"none\", \"none\"]   \n",
       "1      PersonX abandons ___ altogether          [\"none\", \"none\"]   \n",
       "2  PersonX abandons the ___ altogether  [\"none\", \"none\", \"none\"]   \n",
       "3     PersonX abolishes ___ altogether  [\"none\", \"none\", \"none\"]   \n",
       "4  PersonX abolishes ___ in the states                  [\"none\"]   \n",
       "\n",
       "             oReact                                              oWant  \\\n",
       "0  [\"none\", \"none\"]                           [\"none\", \"none\", \"none\"]   \n",
       "1      [\"dejected\"]  [\"none\", \"none\", \"to find a new job for him\", ...   \n",
       "2        [\"defeat\"]  [\"none\", \"to do something else as well\", \"they...   \n",
       "3          [\"none\"]  [\"to be free\", \"to do things of their own wish...   \n",
       "4          [\"none\"]  [\"to celebrate\", \"to write about the new law\",...   \n",
       "\n",
       "                                               xAttr  \\\n",
       "0  [\"avoidant\", \"weak\", \"hurried\", \"late\", \"Tardy...   \n",
       "1  [\"impatient\", \"decisive\", \"undependable\", \"fic...   \n",
       "2  [\"flaky\", \"irresponsible\", \"desperate\", \"convi...   \n",
       "3  [\"ruthless\", \"destructive\", \"strict\", \"determi...   \n",
       "4  [\"bold\", \"authoritative\", \"determined\", \"heroi...   \n",
       "\n",
       "                                             xEffect  \\\n",
       "0  [\"She ran to the bathroom\", \"She finally made ...   \n",
       "1  [\"gets a reputation as a quitter\", \"hangs head...   \n",
       "2  [\"eats all the cakes\", \"abandons his diets too...   \n",
       "3  [\"loss money\", \"change house\", \"get loan\", \"pe...   \n",
       "4                                           [\"none\"]   \n",
       "\n",
       "                                            xIntent  \\\n",
       "0  [\"to go somewhere else more important.\", \"none\"]   \n",
       "1                                    [\"put a stop\"]   \n",
       "2                      [\"to appear not interested\"]   \n",
       "3                   [\"give a punishment in person\"]   \n",
       "4                [\"this is unhappiness for people\"]   \n",
       "\n",
       "                                               xNeed  \\\n",
       "0                           [\"none\", \"none\", \"none\"]   \n",
       "1  [\"Plows the field.\", \"Gets exhausted from it.\"...   \n",
       "2  [\"none\", \"to get frustrated\", \"to determine it...   \n",
       "3  [\"to have a plan\", \"to have a reason\", \"to kno...   \n",
       "4  [\"to find a problem\", \"to find out to stop tha...   \n",
       "\n",
       "                                              xReact  \\\n",
       "0  [\"the person feels happy since he arrived at h...   \n",
       "1                                  [\"authoritative\"]   \n",
       "2                                    [\"pressurized\"]   \n",
       "3                                     [\"he was sad\"]   \n",
       "4                                            [\"sad\"]   \n",
       "\n",
       "                                               xWant  \\\n",
       "0  [\"to escape from him\", \"to resign his job\", \"t...   \n",
       "1  [\"Sell his land.\", \"Was just city.\", \"to start...   \n",
       "2  [\"to go out\", \"to find other place\", \"find som...   \n",
       "3  [\"human to be free\", \"not to feel pain\", \"to m...   \n",
       "4  [\"to enforce the ruling\", \"memorialize the law...   \n",
       "\n",
       "                        prefix split  \n",
       "0             [\"better\", \"go\"]   dev  \n",
       "1   [\"abandons\", \"altogether\"]   trn  \n",
       "2   [\"abandons\", \"altogether\"]   trn  \n",
       "3  [\"abolishes\", \"altogether\"]   trn  \n",
       "4      [\"abolishes\", \"states\"]   trn  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = set(train_df.text.to_list())\n",
    "ood_test = [event for event in atomic_df.event if event not in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ood_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24675/24675 [00:00<00:00, 1083291.83it/s]\n"
     ]
    }
   ],
   "source": [
    "ood_df = pd.DataFrame({'text': ood_test})\n",
    "ood_vocab = create_vocab(ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17363761877690245, 0.8737229260318757)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(ood_vocab)) / len(train_vocab), len(train_vocab.intersection(ood_vocab)) / len(ood_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mismayil/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_wordnet.wordnet_annotator.WordnetAnnotator at 0x7ff0c52bcdc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"spacy_wordnet\", after='tagger', config={'lang': nlp.lang})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('offer.v.01'),\n",
       " Synset('offer.v.02'),\n",
       " Synset('volunteer.v.02'),\n",
       " Synset('offer.v.04'),\n",
       " Synset('offer.v.05'),\n",
       " Synset('offer.v.06'),\n",
       " Synset('offer.v.07'),\n",
       " Synset('offer.v.08'),\n",
       " Synset('offer.v.09'),\n",
       " Synset('put_up.v.02'),\n",
       " Synset('extend.v.04'),\n",
       " Synset('propose.v.05'),\n",
       " Synset('offer.v.13')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp('offered')[0]\n",
    "token._.wordnet.synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'walks',\n",
       " 'now',\n",
       " 'pig',\n",
       " 'lemonade',\n",
       " 'loses',\n",
       " 'offered',\n",
       " 'enjoys',\n",
       " 'airplane',\n",
       " 'taking',\n",
       " 'healthier',\n",
       " 'seriously',\n",
       " 'gardener',\n",
       " 'rent',\n",
       " 'sorry',\n",
       " 'jar',\n",
       " 'balcony',\n",
       " 'time',\n",
       " 'rays',\n",
       " 'trainer',\n",
       " 'beach',\n",
       " 'juice',\n",
       " 'wrench',\n",
       " 'fast',\n",
       " 'interviews',\n",
       " 'chair',\n",
       " 'learn',\n",
       " 'kind',\n",
       " 'hide',\n",
       " 'appreciation',\n",
       " 'infomercial',\n",
       " 'sick',\n",
       " 'shoe',\n",
       " 'tools',\n",
       " 'leg',\n",
       " 'climatic',\n",
       " 'took',\n",
       " 'dirt',\n",
       " 'joy',\n",
       " 'cat',\n",
       " 'posts',\n",
       " 'button',\n",
       " 'stings',\n",
       " 'arm',\n",
       " 'mower',\n",
       " 'carried',\n",
       " 'contains',\n",
       " 'behavior',\n",
       " 'sight',\n",
       " 'dogs',\n",
       " 'things',\n",
       " 'asleep',\n",
       " 'like',\n",
       " 'age',\n",
       " 'news',\n",
       " 'new',\n",
       " 'copies',\n",
       " 'believe',\n",
       " 'pace',\n",
       " 'matters',\n",
       " 'gets',\n",
       " 'snacks',\n",
       " 'worries',\n",
       " 'kingdom',\n",
       " 'go',\n",
       " 'coat',\n",
       " 'disposal',\n",
       " 'consoles',\n",
       " 'ladder',\n",
       " 'decanter',\n",
       " 'publishes',\n",
       " 'rolex',\n",
       " 'dealer',\n",
       " 'tacos',\n",
       " 'presses',\n",
       " 'condition',\n",
       " 'pluto',\n",
       " 'afternoon',\n",
       " 'comfortable',\n",
       " 'cracker',\n",
       " 'theater',\n",
       " 'actor',\n",
       " 'bus',\n",
       " 'applies',\n",
       " 'derives',\n",
       " 'cheese',\n",
       " 'see',\n",
       " 'father',\n",
       " 'firefighter',\n",
       " 'herself',\n",
       " 'station',\n",
       " 'energy',\n",
       " 't',\n",
       " 'spinach',\n",
       " 'cloth',\n",
       " 'nips',\n",
       " 'pathway',\n",
       " 'f',\n",
       " 'chin',\n",
       " 'doors',\n",
       " 'victim',\n",
       " 'storms',\n",
       " 'give',\n",
       " 'cartoons',\n",
       " 'banjo',\n",
       " 'ever',\n",
       " 'lives',\n",
       " 'jewish',\n",
       " 'pretty',\n",
       " 'shawl',\n",
       " 'barbershop',\n",
       " 'communicate',\n",
       " 'reward',\n",
       " 'combination',\n",
       " 'represents',\n",
       " 'hammer',\n",
       " 'ease',\n",
       " 'suits',\n",
       " 'attempt',\n",
       " 'studying',\n",
       " 'panel',\n",
       " 'transmits',\n",
       " 'silk',\n",
       " 'bakes',\n",
       " 'floor',\n",
       " 'over',\n",
       " 'talking',\n",
       " 'band',\n",
       " 'female',\n",
       " 'more',\n",
       " 'injures',\n",
       " 'balm',\n",
       " 'another',\n",
       " 'camps',\n",
       " 'tray',\n",
       " 'tomatoes',\n",
       " 'extra',\n",
       " 'binder',\n",
       " 'collects',\n",
       " 'barrier',\n",
       " 'odd',\n",
       " 'skiing',\n",
       " 'touches',\n",
       " 'resigns',\n",
       " 'hollow',\n",
       " 'drank',\n",
       " 'swing',\n",
       " 'horseback',\n",
       " 'married',\n",
       " 'membership',\n",
       " 'pardons',\n",
       " 'choice',\n",
       " 'shoes',\n",
       " 'japanese',\n",
       " 'contract',\n",
       " 'eventually',\n",
       " 'signal',\n",
       " 'prevents',\n",
       " 'plug',\n",
       " 'warehouse',\n",
       " 'cheque',\n",
       " 'perfects',\n",
       " '/',\n",
       " 'clean',\n",
       " 'possesses',\n",
       " 'vacuum',\n",
       " 'tram',\n",
       " 'canada',\n",
       " 'ratchet',\n",
       " 'printer',\n",
       " 'shirt',\n",
       " 'shoots',\n",
       " 'within',\n",
       " 'croquet',\n",
       " 'panic',\n",
       " 'score',\n",
       " 'adores',\n",
       " '2013',\n",
       " 'have',\n",
       " 'creeps',\n",
       " 'shop',\n",
       " 'recipe',\n",
       " 'relatives',\n",
       " 'drawer',\n",
       " 'distributes',\n",
       " 'projects',\n",
       " 'pregnant',\n",
       " 'bathwater',\n",
       " 'dresses',\n",
       " 'reads',\n",
       " 'robin',\n",
       " 'entrance',\n",
       " 'piggy',\n",
       " 'skin',\n",
       " 'steps',\n",
       " 'rings',\n",
       " 'hymn',\n",
       " 'tangled',\n",
       " 'speeds',\n",
       " 'others',\n",
       " 'which',\n",
       " 'toy',\n",
       " 'scale',\n",
       " 'flowers',\n",
       " 'stars',\n",
       " 'hiding',\n",
       " 'swatter',\n",
       " 'setting',\n",
       " 'boots',\n",
       " 'wild',\n",
       " 'auditorium',\n",
       " 'prevent',\n",
       " 'announcement',\n",
       " 'ointment',\n",
       " 'kettle',\n",
       " 'sand',\n",
       " 'food',\n",
       " 'overhead',\n",
       " 'drops',\n",
       " 'flu',\n",
       " 'timetable',\n",
       " 'abroad',\n",
       " 'candles',\n",
       " 'inference',\n",
       " 'films',\n",
       " 'garage',\n",
       " 'describe',\n",
       " 'good',\n",
       " 'summer',\n",
       " 'teaches',\n",
       " 'breath',\n",
       " 'corrects',\n",
       " 'knows',\n",
       " 'lends',\n",
       " 'rabid',\n",
       " 'does',\n",
       " 'merchant',\n",
       " 'sketch',\n",
       " 'forehead',\n",
       " 'sweats',\n",
       " 'veterinarian',\n",
       " 'evaluates',\n",
       " 'adds',\n",
       " 'than',\n",
       " 'flora',\n",
       " 'messaging',\n",
       " 'turnstile',\n",
       " 'launches',\n",
       " 'acquaintance',\n",
       " 'reveals',\n",
       " 'big',\n",
       " 'missed',\n",
       " 'gains',\n",
       " 'conquers',\n",
       " 'stand',\n",
       " 'tripod',\n",
       " 'fate',\n",
       " 'flag',\n",
       " 'accepted',\n",
       " 'government',\n",
       " 'affords',\n",
       " 'expresses',\n",
       " 'naughty',\n",
       " 'cosmic',\n",
       " 'bitter',\n",
       " 'jewelry',\n",
       " 'can',\n",
       " 'thesis',\n",
       " 'photocopies',\n",
       " 'guage',\n",
       " 'opinion',\n",
       " 'pleased',\n",
       " 'goalie',\n",
       " 'tea',\n",
       " 'scratch',\n",
       " 'aquarium',\n",
       " 'hightails',\n",
       " 'earth',\n",
       " 'ambulance',\n",
       " 'pulled',\n",
       " 'alarm',\n",
       " 'air',\n",
       " 'quotes',\n",
       " 'win',\n",
       " 'scrambles',\n",
       " 'monument',\n",
       " 'presentation',\n",
       " 'calling',\n",
       " 'knee',\n",
       " 'suspension',\n",
       " 'delivery',\n",
       " 'ashamed',\n",
       " 'power',\n",
       " 'realizes',\n",
       " 'term',\n",
       " 'points',\n",
       " 'blower',\n",
       " 'teach',\n",
       " 'expedition',\n",
       " 'fill',\n",
       " 'reproduces',\n",
       " 'replacement',\n",
       " 'pen',\n",
       " 'belongings',\n",
       " 'both',\n",
       " 'vest',\n",
       " 'roast',\n",
       " 'rabbit',\n",
       " 'engine',\n",
       " 'actions',\n",
       " 'arch',\n",
       " 'next',\n",
       " 'bacon',\n",
       " 'persony',\n",
       " 'provide',\n",
       " 'music',\n",
       " 'example',\n",
       " 'frightens',\n",
       " 'engagement',\n",
       " 'poor',\n",
       " 'swallows',\n",
       " 'auto',\n",
       " 'frosting',\n",
       " 'cape',\n",
       " 'restores',\n",
       " 'check',\n",
       " 'skills',\n",
       " 'angry',\n",
       " 'recommendation',\n",
       " 'paces',\n",
       " 'sprays',\n",
       " 'cereal',\n",
       " 'laundry',\n",
       " 'sister',\n",
       " 'attire',\n",
       " 'cookbook',\n",
       " 'as',\n",
       " 'landline',\n",
       " 'knowledge',\n",
       " 'harm',\n",
       " 'pray',\n",
       " 'barbecue',\n",
       " 'permit',\n",
       " 'nap',\n",
       " 'waits',\n",
       " 'repairman',\n",
       " 'survival',\n",
       " 'fear',\n",
       " 'stock',\n",
       " 'airline',\n",
       " 'researches',\n",
       " 'socks',\n",
       " 'catalog',\n",
       " 'minute',\n",
       " 'kosher',\n",
       " 'keys',\n",
       " 'jeep',\n",
       " 'player',\n",
       " 'radiation',\n",
       " 'excited',\n",
       " 'blocks',\n",
       " 'door',\n",
       " 'dates',\n",
       " 'pizza',\n",
       " 'sitting',\n",
       " 'terrifies',\n",
       " 'stares',\n",
       " 'edge',\n",
       " 'salad',\n",
       " 'early',\n",
       " 'heart',\n",
       " 'saw',\n",
       " 'question',\n",
       " 'grabbed',\n",
       " 'leek',\n",
       " 'runs',\n",
       " 'level',\n",
       " 'blinds',\n",
       " 'exceeds',\n",
       " 'conduct',\n",
       " 'hangs',\n",
       " 'boogie',\n",
       " 'surgery',\n",
       " 'road',\n",
       " 'flyer',\n",
       " 'regulates',\n",
       " 'cake',\n",
       " 'war',\n",
       " 'delivers',\n",
       " 'instruction',\n",
       " 'cats',\n",
       " 'animal',\n",
       " 'soda',\n",
       " 'grinder',\n",
       " 'tan',\n",
       " 'realtor',\n",
       " 'swimsuit',\n",
       " 'billboard',\n",
       " 'any',\n",
       " 'lip',\n",
       " 'warm',\n",
       " 'solar',\n",
       " 'focus',\n",
       " 'thee',\n",
       " 'answer',\n",
       " 'awake',\n",
       " 'artist',\n",
       " 'rank',\n",
       " 'increase',\n",
       " 'extends',\n",
       " 'mind',\n",
       " 'happily',\n",
       " 'flies',\n",
       " 'tape',\n",
       " 'pain',\n",
       " 'being',\n",
       " 'heads',\n",
       " 'dandruff',\n",
       " 'healthy',\n",
       " 'impression',\n",
       " 'rampant',\n",
       " 'beverage',\n",
       " 'pottery',\n",
       " 'competition',\n",
       " 'merlot',\n",
       " 'set',\n",
       " 'problem',\n",
       " 'horn',\n",
       " 'longer',\n",
       " 'sash',\n",
       " 'curtain',\n",
       " 'dryer',\n",
       " 'around',\n",
       " 'shady',\n",
       " 'mud',\n",
       " 'real',\n",
       " 'pleasure',\n",
       " 'hard',\n",
       " 'idiot',\n",
       " 'diabetes',\n",
       " 'axe',\n",
       " 'memo',\n",
       " 'stools',\n",
       " 'fit',\n",
       " 'wax',\n",
       " 'farm',\n",
       " 'fruits',\n",
       " 'visit',\n",
       " 'baseball',\n",
       " 'tourist',\n",
       " 'lately',\n",
       " 'slot',\n",
       " 'guns',\n",
       " 'wrestles',\n",
       " 'lotion',\n",
       " 'performer',\n",
       " 'effect',\n",
       " 'walk',\n",
       " 'rises',\n",
       " 'interests',\n",
       " 'maker',\n",
       " 'easier',\n",
       " 'summons',\n",
       " 'peroxide',\n",
       " 'spills',\n",
       " 'closet',\n",
       " 'reading',\n",
       " 'final',\n",
       " 'identity',\n",
       " 'hurry',\n",
       " 'pump',\n",
       " 'pays',\n",
       " 'cleaning',\n",
       " 'handheld',\n",
       " 'cups',\n",
       " 'wheel',\n",
       " 'suite',\n",
       " 'terms',\n",
       " 'apart',\n",
       " 'clearly',\n",
       " 'refuses',\n",
       " 'footwear',\n",
       " 'understands',\n",
       " 'taxiway',\n",
       " 'budget',\n",
       " 'base',\n",
       " 'rewards',\n",
       " 'pills',\n",
       " 'enlightens',\n",
       " 'different',\n",
       " 'rolls',\n",
       " 'messages',\n",
       " 'opportunity',\n",
       " 'favorite',\n",
       " 'magic',\n",
       " 'drives',\n",
       " 'encourages',\n",
       " 'found',\n",
       " 'course',\n",
       " 'elects',\n",
       " 'restaurant',\n",
       " 'street',\n",
       " 'ship',\n",
       " 'credit',\n",
       " 'magazine',\n",
       " 'copy',\n",
       " 'shoves',\n",
       " 'whole',\n",
       " 'prescription',\n",
       " 'smell',\n",
       " 'awful',\n",
       " 'write',\n",
       " 'book',\n",
       " 'application',\n",
       " 'song',\n",
       " 'movement',\n",
       " 'analyst',\n",
       " 'showers',\n",
       " 'bit',\n",
       " 'i',\n",
       " 'flood',\n",
       " 'comedy',\n",
       " 'grew',\n",
       " 'bits',\n",
       " 'usb',\n",
       " 'tube',\n",
       " 'saves',\n",
       " 'argues',\n",
       " 'stumps',\n",
       " 'conference',\n",
       " 'shares',\n",
       " 'plaster',\n",
       " 'grass',\n",
       " 'tress',\n",
       " 'contact',\n",
       " 'article',\n",
       " 'open',\n",
       " 'swimmer',\n",
       " 'snazzy',\n",
       " 'bath',\n",
       " 'consulting',\n",
       " 'cord',\n",
       " 'mountains',\n",
       " 'display',\n",
       " 'posters',\n",
       " 'files',\n",
       " 'lays',\n",
       " 'kiss',\n",
       " 'sew',\n",
       " 'shark',\n",
       " 'stay',\n",
       " 'peacefully',\n",
       " 'all',\n",
       " 'solution',\n",
       " 'market',\n",
       " 'forth',\n",
       " 'yells',\n",
       " 'hand',\n",
       " 'homeless',\n",
       " 'hit',\n",
       " 'race',\n",
       " 'local',\n",
       " 'juices',\n",
       " 'utterance',\n",
       " 'cv',\n",
       " 'award',\n",
       " 'screen',\n",
       " 'months',\n",
       " 'improves',\n",
       " 'chips',\n",
       " 'springs',\n",
       " 'almost',\n",
       " 'stuff',\n",
       " 'sense',\n",
       " 'sink',\n",
       " 'march',\n",
       " 'bay',\n",
       " 'pours',\n",
       " 'bell',\n",
       " 'aerial',\n",
       " 'shouts',\n",
       " 'personz',\n",
       " 'putteth',\n",
       " 'purchases',\n",
       " 'lorry',\n",
       " 'moon',\n",
       " 'started',\n",
       " 'vows',\n",
       " 'scanner',\n",
       " 'reference',\n",
       " 'important',\n",
       " 'mat',\n",
       " 'guarantee',\n",
       " 'aid',\n",
       " 'gently',\n",
       " 'busy',\n",
       " 'skips',\n",
       " 'confused',\n",
       " 'politics',\n",
       " 'forgive',\n",
       " 'bench',\n",
       " 'personal',\n",
       " 'seed',\n",
       " 'headstone',\n",
       " 'someone',\n",
       " 'ink',\n",
       " 'jacket',\n",
       " 'want',\n",
       " 'straight',\n",
       " 'walking',\n",
       " 'made',\n",
       " 'apps',\n",
       " 'diving',\n",
       " 'cashier',\n",
       " 'offer',\n",
       " 'offering',\n",
       " 'backpack',\n",
       " 'sprains',\n",
       " 'practiced',\n",
       " 'stub',\n",
       " 'rod',\n",
       " 'sleeve',\n",
       " 'links',\n",
       " 'drink',\n",
       " 'parrot',\n",
       " 'salon',\n",
       " 'crumb',\n",
       " 'florida',\n",
       " 'homework',\n",
       " 'copay',\n",
       " 'junk',\n",
       " 'cherry',\n",
       " 'either',\n",
       " 'creates',\n",
       " 'matches',\n",
       " 'nature',\n",
       " 'lunar',\n",
       " 'to',\n",
       " 'wrist',\n",
       " 'color',\n",
       " 'begs',\n",
       " 'drugs',\n",
       " 'report',\n",
       " 'death',\n",
       " 'directs',\n",
       " 'dry',\n",
       " 'deer',\n",
       " 'laptop',\n",
       " 'irs',\n",
       " 'stories',\n",
       " 'conditions',\n",
       " 'wolf',\n",
       " 'cries',\n",
       " 'shake',\n",
       " 'shaves',\n",
       " 'price',\n",
       " 'shuttle',\n",
       " 'needed',\n",
       " 'bird',\n",
       " 'large',\n",
       " 'driver',\n",
       " 'surface',\n",
       " 'amazon',\n",
       " 'raises',\n",
       " 'dyes',\n",
       " 'join',\n",
       " 'learns',\n",
       " 'pickup',\n",
       " 'bowler',\n",
       " 'starves',\n",
       " 'trips',\n",
       " 'baking',\n",
       " 'calm',\n",
       " 'fences',\n",
       " 'finishes',\n",
       " 'file',\n",
       " 'key',\n",
       " 'dead',\n",
       " 'visits',\n",
       " 'english',\n",
       " 'lady',\n",
       " 'other',\n",
       " 'gods',\n",
       " 'interview',\n",
       " 'feed',\n",
       " 'office',\n",
       " 'against',\n",
       " 'essay',\n",
       " 'spiral',\n",
       " 'describes',\n",
       " 'jogging',\n",
       " 'clerk',\n",
       " 'honor',\n",
       " 'lunch',\n",
       " 'engineer',\n",
       " 'atm',\n",
       " 'crap',\n",
       " 'live',\n",
       " 'scalpel',\n",
       " 'elected',\n",
       " 'sandwiches',\n",
       " 'lines',\n",
       " 'standard',\n",
       " 'thought',\n",
       " 'infection',\n",
       " 'elderly',\n",
       " 'spoon',\n",
       " 'chokes',\n",
       " 'tank',\n",
       " 'releases',\n",
       " 'serviette',\n",
       " 'woods',\n",
       " 'scooper',\n",
       " 'tickles',\n",
       " 'knock',\n",
       " 'iron',\n",
       " 'cone',\n",
       " 'cover',\n",
       " 'comes',\n",
       " 'minds',\n",
       " 'through',\n",
       " 'pumps',\n",
       " 'racks',\n",
       " 'address',\n",
       " 'child',\n",
       " 'tips',\n",
       " 'burner',\n",
       " 'hour',\n",
       " 'grants',\n",
       " 'salesman',\n",
       " 'hurting',\n",
       " 'ensures',\n",
       " 'loft',\n",
       " 'minutes',\n",
       " 'little',\n",
       " 'telephone',\n",
       " 'middle',\n",
       " 'stamp',\n",
       " 'settles',\n",
       " 'hall',\n",
       " 'sheet',\n",
       " 'examines',\n",
       " 'cry',\n",
       " 'outlines',\n",
       " 'uneasy',\n",
       " 'network',\n",
       " 'happen',\n",
       " 'tests',\n",
       " 'ceremony',\n",
       " 'dog',\n",
       " 'drum',\n",
       " 'airport',\n",
       " 'interprets',\n",
       " 'perfect',\n",
       " 'climbs',\n",
       " 'hires',\n",
       " 'police',\n",
       " 'uses',\n",
       " 'history',\n",
       " 'dating',\n",
       " 'warmly',\n",
       " 'energetic',\n",
       " 'recognizes',\n",
       " 'pressure',\n",
       " 'rather',\n",
       " 'space',\n",
       " 'analysis',\n",
       " 'pies',\n",
       " 'nose',\n",
       " 'iphone',\n",
       " 'knocked',\n",
       " 'adhesive',\n",
       " 'making',\n",
       " 'draws',\n",
       " 'lizard',\n",
       " 'student',\n",
       " 'health',\n",
       " 'contest',\n",
       " 'policeman',\n",
       " 'washer',\n",
       " 'shotgun',\n",
       " 'quilt',\n",
       " 'step',\n",
       " \"'\",\n",
       " 'tells',\n",
       " 'bass',\n",
       " 'department',\n",
       " 'cakes',\n",
       " 'pigeons',\n",
       " 'lengths',\n",
       " 'fulfills',\n",
       " 'preacher',\n",
       " 'wears',\n",
       " 'start',\n",
       " 'basket',\n",
       " 'bacterial',\n",
       " 'sale',\n",
       " 'wool',\n",
       " 'trees',\n",
       " 'bang',\n",
       " 'sends',\n",
       " 'but',\n",
       " 'closely',\n",
       " 'daily',\n",
       " 'ready',\n",
       " 'gender',\n",
       " 'ant',\n",
       " 'sluggish',\n",
       " 'pots',\n",
       " 'lock',\n",
       " 'separate',\n",
       " 'interest',\n",
       " 'guards',\n",
       " 'kit',\n",
       " 'journey',\n",
       " 'misses',\n",
       " 'action',\n",
       " 'waiter',\n",
       " 'maps',\n",
       " 'forget',\n",
       " 'smells',\n",
       " 'roadway',\n",
       " 'milks',\n",
       " 'sneaks',\n",
       " 'lawyer',\n",
       " 'bonus',\n",
       " 'pipe',\n",
       " 'shore',\n",
       " 'green',\n",
       " 'outlet',\n",
       " 'fries',\n",
       " 'using',\n",
       " 'board',\n",
       " 'environment',\n",
       " 'deeply',\n",
       " 'truckin',\n",
       " 'iv',\n",
       " 'bicycle',\n",
       " 'bubbles',\n",
       " 'roommate',\n",
       " 'king',\n",
       " 'everyday',\n",
       " 'children',\n",
       " 'combs',\n",
       " 'wonderful',\n",
       " 'manner',\n",
       " 'material',\n",
       " 'each',\n",
       " 'prep',\n",
       " 'skunk',\n",
       " 'professional',\n",
       " 'murder',\n",
       " 'skating',\n",
       " 'plasma',\n",
       " 'youtube',\n",
       " 'cooking',\n",
       " 'leak',\n",
       " 'hinge',\n",
       " 'ask',\n",
       " 'thinks',\n",
       " 'control',\n",
       " 'safe',\n",
       " 'dances',\n",
       " 'breakfast',\n",
       " 'oregano',\n",
       " 'fees',\n",
       " 'blood',\n",
       " 'limb',\n",
       " 'sells',\n",
       " 'tail',\n",
       " 'wet',\n",
       " 'string',\n",
       " 'pack',\n",
       " 'produces',\n",
       " 'attorney',\n",
       " 'company',\n",
       " 'window',\n",
       " 'huge',\n",
       " 'city',\n",
       " 'mood',\n",
       " 'isle',\n",
       " 'call',\n",
       " 'traps',\n",
       " 'prison',\n",
       " 'jerks',\n",
       " 'front',\n",
       " 'approaches',\n",
       " 'pokes',\n",
       " 'detective',\n",
       " 'these',\n",
       " 'great',\n",
       " 'pantry',\n",
       " 'listens',\n",
       " 'uncle',\n",
       " 'there',\n",
       " 'wastes',\n",
       " 'tomorrow',\n",
       " 'motorized',\n",
       " 'alters',\n",
       " 'wood',\n",
       " 'assignment',\n",
       " 'shorts',\n",
       " 'charge',\n",
       " 'drapes',\n",
       " 'use',\n",
       " 'measuring',\n",
       " 'regularly',\n",
       " 'eat',\n",
       " 'castles',\n",
       " 'merchandise',\n",
       " 'lid',\n",
       " 'scuba',\n",
       " 'crying',\n",
       " 'item',\n",
       " 'orchestra',\n",
       " 'snack',\n",
       " 'watch',\n",
       " 'crab',\n",
       " 'ficus',\n",
       " 'hurts',\n",
       " 'rake',\n",
       " 'split',\n",
       " 'gazes',\n",
       " 'mop',\n",
       " 'jokes',\n",
       " 'fan',\n",
       " 'center',\n",
       " 'dye',\n",
       " 'after',\n",
       " 'tin',\n",
       " 'fix',\n",
       " 'burgers',\n",
       " 'radar',\n",
       " '5',\n",
       " 'pick',\n",
       " 'dad',\n",
       " 'burned',\n",
       " 'rain',\n",
       " 'strikes',\n",
       " 'keenly',\n",
       " 'left',\n",
       " 'follow',\n",
       " 'welkin',\n",
       " 'rug',\n",
       " 'showed',\n",
       " 'gauze',\n",
       " 'mold',\n",
       " 'plutonium',\n",
       " 'taxi',\n",
       " 'proof',\n",
       " 'waiting',\n",
       " 'online',\n",
       " 'length',\n",
       " 'embraces',\n",
       " 'smoothies',\n",
       " 'tomato',\n",
       " 'canteen',\n",
       " 'sunscreen',\n",
       " 'advance',\n",
       " 'pasta',\n",
       " 'moose',\n",
       " 'cried',\n",
       " 'remains',\n",
       " 'knocks',\n",
       " 'golfing',\n",
       " 'hospital',\n",
       " 'sweat',\n",
       " 'toast',\n",
       " 'though',\n",
       " 'include',\n",
       " 'flea',\n",
       " 'mess',\n",
       " 'solves',\n",
       " 'that',\n",
       " 'blue',\n",
       " 'got',\n",
       " 'study',\n",
       " 'pets',\n",
       " 'practices',\n",
       " 'function',\n",
       " 'bowls',\n",
       " 'store',\n",
       " 'reports',\n",
       " 'profusely',\n",
       " 'tightens',\n",
       " 'apple',\n",
       " 'asks',\n",
       " 'tongue',\n",
       " 'purchase',\n",
       " 'position',\n",
       " 'no',\n",
       " 'assigns',\n",
       " 'mistake',\n",
       " 'quits',\n",
       " 'cannon',\n",
       " 'slip',\n",
       " 'rack',\n",
       " 'world',\n",
       " 'exercise',\n",
       " 'spray',\n",
       " 'sample',\n",
       " ...}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vocab.intersection(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "transomcs_df = pd.read_csv(\"data/TransOMCS_full.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>student</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>school</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>building</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sugar</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>coffee</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>school</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         head    relation    tail  score\n",
       "0     student  AtLocation  school    1.0\n",
       "1    building  AtLocation    city    1.0\n",
       "2       sugar  AtLocation  coffee    1.0\n",
       "3  government  AtLocation    city    1.0\n",
       "4      school  AtLocation    city    1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>fasten</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>warranty</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108082</th>\n",
       "      <td>work</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114095</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>read</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124334</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>lure</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18379073</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>dereference</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18379482</th>\n",
       "      <td>ping</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>betrothal</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18438389</th>\n",
       "      <td>uptight</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18444109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             head        relation         tail  score\n",
       "38215         NaN  ReceivesAction       fasten   0.99\n",
       "73145         NaN      InstanceOf     warranty   0.99\n",
       "108082       work  ReceivesAction          NaN   0.99\n",
       "114095        NaN  ReceivesAction         read   0.99\n",
       "124334        NaN  ReceivesAction         lure   0.99\n",
       "...           ...             ...          ...    ...\n",
       "18379073      NaN  ReceivesAction  dereference   0.00\n",
       "18379482     ping  ReceivesAction          NaN   0.00\n",
       "18406398      NaN      InstanceOf    betrothal   0.00\n",
       "18438389  uptight      InstanceOf          NaN   0.00\n",
       "18444109      NaN      AtLocation          NaN   0.00\n",
       "\n",
       "[954 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df[transomcs_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transomcs_df = transomcs_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18480653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transomcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df.duplicated(subset=['head']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.relation import CONCEPTNET_TO_ATOMIC_MAP, PHYSICAL_RELATIONS, EVENT_RELATIONS, SOCIAL_RELATIONS\n",
    "from collections import defaultdict\n",
    "\n",
    "def relation_to_class(relation):\n",
    "    if relation in PHYSICAL_RELATIONS:\n",
    "        return 0\n",
    "    \n",
    "    if relation in EVENT_RELATIONS:\n",
    "        return 1\n",
    "    \n",
    "    if relation in SOCIAL_RELATIONS:\n",
    "        return 2\n",
    "    \n",
    "    return None\n",
    "\n",
    "test_ood_samples = []\n",
    "unrecognized_rels = set()\n",
    "head_label_map = defaultdict(set)\n",
    "\n",
    "for row in transomcs_df.itertuples():\n",
    "    heads = row.head.split()\n",
    "    if not any([head in train_vocab for head in heads]):\n",
    "        label = [0, 0, 0]\n",
    "        rel_class = relation_to_class(row.relation)\n",
    "        if rel_class is None:\n",
    "            atomic_relations = CONCEPTNET_TO_ATOMIC_MAP.get(row.relation)\n",
    "            if atomic_relations:\n",
    "                if not isinstance(atomic_relations, list):\n",
    "                    atomic_relations = [atomic_relations]\n",
    "                \n",
    "                for rel in atomic_relations:\n",
    "                    rel_class = relation_to_class(rel)\n",
    "                    head_label_map[row.head].add(rel_class)\n",
    "            else:\n",
    "                unrecognized_rels.add(row.relation)\n",
    "        else:\n",
    "            head_label_map[row.head].add(rel_class)\n",
    "\n",
    "for head, labels in head_label_map.items():\n",
    "    final_label = [1 if label in labels else 0 for label in range(3)]\n",
    "    test_ood_samples.append((head, final_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72407"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ood_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CreatedBy', 'InstanceOf'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrecognized_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_df = pd.DataFrame(test_ood_samples, columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>curator</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foyer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yolk</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fade</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pave</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text      label\n",
       "0  curator  [1, 1, 1]\n",
       "1    foyer  [1, 1, 1]\n",
       "2     yolk  [1, 1, 1]\n",
       "3     fade  [1, 1, 1]\n",
       "4     pave  [1, 1, 1]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_df = explode_labels(test_ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    72266\n",
       " 0      141\n",
       " Name: label_0, dtype: int64,\n",
       " 1    44593\n",
       " 0    27814\n",
       " Name: label_1, dtype: int64,\n",
       " 0    56184\n",
       " 1    16223\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_df.label_0.value_counts(), test_ood_df.label_1.value_counts(), test_ood_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kogito.core.processors.relation import SWEMRelationClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import spacy\n",
    "from relation_modeling_utils import HeadDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "vocab = np.load(\n",
    "    \"./data/vocab_glove_100d.npy\", allow_pickle=True\n",
    ").item()\n",
    "\n",
    "swem_classifier = SWEMRelationClassifier(pooling=\"avg\")\n",
    "swem_classifier.load_state_dict(\n",
    "    torch.load(\n",
    "        \"./models/swem_multi_label_finetune_state_dict.pth\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "swem_test_data = HeadDataset(test_ood_df, vocab=vocab)\n",
    "swem_test_dataloader = DataLoader(swem_test_data, batch_size=len(swem_test_data), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    swem_X, swem_y = next(iter(swem_test_dataloader))\n",
    "    swem_preds = swem_classifier.forward(swem_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def report_metrics(preds, y):\n",
    "    test_accuracy = torchmetrics.Accuracy()\n",
    "    test_precision = torchmetrics.Precision(num_classes=3, average=\"weighted\")\n",
    "    test_recall = torchmetrics.Recall(num_classes=3, average=\"weighted\")\n",
    "    test_f1 = torchmetrics.F1Score(num_classes=3, average=\"weighted\")\n",
    "    print(f'Test accuracy={test_accuracy(preds, y).item():.3f}, precision={test_precision(preds, y).item():.3f}, recall={test_recall(preds, y).item():.3f}, f1={test_f1(preds, y).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy=0.544, precision=0.712, recall=0.461, f1=0.552\n"
     ]
    }
   ],
   "source": [
    "report_metrics(swem_preds, swem_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DistilBertHeadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.labels = np.asarray(df['label'].to_list())\n",
    "        self.texts = [self.tokenizer(text, padding='max_length', max_length=32, truncation=True,\n",
    "                                     return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class DistilBERTClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3, dropout=0.5, learning_rate=1e-4, freeze_emb=False):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "\n",
    "        if freeze_emb:\n",
    "            for parameter in self.distilbert.parameters():\n",
    "                parameter.requires_grad = False\n",
    "            self.classifier = nn.Sequential(self.linear)\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(self.dropout, self.linear)\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        outputs = self.classifier(outputs[0][:, 0, :])\n",
    "        return outputs\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        mask = X['attention_mask']\n",
    "        input_ids = X['input_ids'].squeeze(1)\n",
    "        outputs = self.forward(input_ids, mask)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "distilbert_classifier = DistilBERTClassifier.load_from_checkpoint('./models/distilbert_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_test_data = DistilBertHeadDataset(test_ood_df)\n",
    "dbert_test_dataloader = DataLoader(dbert_test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/Users/mismayil/opt/anaconda3/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 1/566 [00:04<43:47,  4.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/opt/anaconda3/envs/kogito/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting:   2%|▏         | 12/566 [00:54<41:34,  4.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/opt/anaconda3/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()\n",
    "d_preds = trainer.predict(distilbert_classifier, dbert_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_metrics(d_preds, y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
