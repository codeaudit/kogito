{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import load_data\n",
    "\n",
    "train_df = load_data(\"data/atomic2020_data-feb2021/train.tsv\", multi_label=True)\n",
    "val_df = load_data(\"data/atomic2020_data-feb2021/dev.tsv\", multi_label=True)\n",
    "test_df = load_data(\"data/atomic2020_data-feb2021/test.tsv\", multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36940, 2962, 6569)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abolishes ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abolishes ___ in the states</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abolishes the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text      label\n",
       "0       PersonX abandons ___ altogether  [0, 0, 1]\n",
       "1   PersonX abandons the ___ altogether  [0, 1, 1]\n",
       "2      PersonX abolishes ___ altogether  [0, 1, 1]\n",
       "3   PersonX abolishes ___ in the states  [0, 1, 1]\n",
       "4  PersonX abolishes the ___ altogether  [0, 1, 1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_labels(df):\n",
    "    df['label_0'] = df.label.apply(lambda l: l[0])\n",
    "    df['label_1'] = df.label.apply(lambda l: l[1])\n",
    "    df['label_2'] = df.label.apply(lambda l: l[2])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = explode_labels(train_df), explode_labels(val_df), explode_labels(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    22457\n",
       " 1    14483\n",
       " Name: label_0, dtype: int64,\n",
       " 0    18538\n",
       " 1    18402\n",
       " Name: label_1, dtype: int64,\n",
       " 1    21006\n",
       " 0    15934\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.label_0.value_counts(), train_df.label_1.value_counts(), train_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    2630\n",
       " 1     332\n",
       " Name: label_0, dtype: int64,\n",
       " 1    2263\n",
       " 0     699\n",
       " Name: label_1, dtype: int64,\n",
       " 1    2228\n",
       " 0     734\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.label_0.value_counts(), val_df.label_1.value_counts(), val_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    4668\n",
       " 1    1901\n",
       " Name: label_0, dtype: int64,\n",
       " 1    4419\n",
       " 0    2150\n",
       " Name: label_1, dtype: int64,\n",
       " 0    3996\n",
       " 1    2573\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label_0.value_counts(), test_df.label_1.value_counts(), test_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140049/140049 [00:00<00:00, 1250496.19it/s]\n",
      "100%|██████████| 14524/14524 [00:00<00:00, 1389649.64it/s]\n",
      "100%|██████████| 27270/27270 [00:00<00:00, 1327083.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "\n",
    "def create_vocab(data):\n",
    "    vocab = set()\n",
    "    text = \" \".join(data.text.to_list())\n",
    "    doc = nlp(text)\n",
    "    for token in tqdm(doc, total=len(doc)):\n",
    "        vocab.add(token.text.lower())\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "train_vocab, val_vocab, test_vocab = create_vocab(train_df), create_vocab(val_df), create_vocab(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15235929505400797, 0.8725581395348837)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(val_vocab)) / len(train_vocab), len(train_vocab.intersection(val_vocab)) / len(val_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27109559002680095, 0.8000958772770853)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(test_vocab)) / len(train_vocab), len(train_vocab.intersection(test_vocab)) / len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "atomic_df = pd.read_csv(\"data/atomic/v4_atomic_all_agg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = set(train_df.text.to_list())\n",
    "ood_test = [event for event in atomic_df.event if event not in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24312"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4617"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ood_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_df = pd.DataFrame({'text': ood_test})\n",
    "ood_vocab = create_vocab(ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17363761877690245, 0.8737229260318757)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab.intersection(ood_vocab)) / len(train_vocab), len(train_vocab.intersection(ood_vocab)) / len(ood_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_wordnet.wordnet_annotator.WordnetAnnotator at 0x7ff0c52bcdc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(\"spacy_wordnet\", after='tagger', config={'lang': nlp.lang})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('offer.v.01'),\n",
       " Synset('offer.v.02'),\n",
       " Synset('volunteer.v.02'),\n",
       " Synset('offer.v.04'),\n",
       " Synset('offer.v.05'),\n",
       " Synset('offer.v.06'),\n",
       " Synset('offer.v.07'),\n",
       " Synset('offer.v.08'),\n",
       " Synset('offer.v.09'),\n",
       " Synset('put_up.v.02'),\n",
       " Synset('extend.v.04'),\n",
       " Synset('propose.v.05'),\n",
       " Synset('offer.v.13')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = nlp('offered')[0]\n",
    "token._.wordnet.synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab.intersection(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "transomcs_df = pd.read_csv(\"data/TransOMCS_full.txt\", sep=\"\\t\", header=None, names=[\"head\", \"relation\", \"tail\", \"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>student</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>school</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>building</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sugar</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>coffee</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>school</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         head    relation    tail  score\n",
       "0     student  AtLocation  school    1.0\n",
       "1    building  AtLocation    city    1.0\n",
       "2       sugar  AtLocation  coffee    1.0\n",
       "3  government  AtLocation    city    1.0\n",
       "4      school  AtLocation    city    1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18481607"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transomcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>student</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>school</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>building</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sugar</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>coffee</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>government</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>school</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>city</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370463</th>\n",
       "      <td>bribe</td>\n",
       "      <td>UsedFor</td>\n",
       "      <td>lend</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370464</th>\n",
       "      <td>jefferson</td>\n",
       "      <td>HasA</td>\n",
       "      <td>county</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370465</th>\n",
       "      <td>man</td>\n",
       "      <td>UsedFor</td>\n",
       "      <td>give to</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370466</th>\n",
       "      <td>sender</td>\n",
       "      <td>UsedFor</td>\n",
       "      <td>know</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5370467</th>\n",
       "      <td>lack</td>\n",
       "      <td>CapableOf</td>\n",
       "      <td>meaning</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5370468 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               head    relation     tail  score\n",
       "0           student  AtLocation   school   1.00\n",
       "1          building  AtLocation     city   1.00\n",
       "2             sugar  AtLocation   coffee   1.00\n",
       "3        government  AtLocation     city   1.00\n",
       "4            school  AtLocation     city   1.00\n",
       "...             ...         ...      ...    ...\n",
       "5370463       bribe     UsedFor     lend   0.51\n",
       "5370464   jefferson        HasA   county   0.51\n",
       "5370465         man     UsedFor  give to   0.51\n",
       "5370466      sender     UsedFor     know   0.51\n",
       "5370467        lack   CapableOf  meaning   0.51\n",
       "\n",
       "[5370468 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df[transomcs_df['score'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38215</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>fasten</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73145</th>\n",
       "      <td>NaN</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>warranty</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108082</th>\n",
       "      <td>work</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114095</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>read</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124334</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>lure</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18379073</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>dereference</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18379482</th>\n",
       "      <td>ping</td>\n",
       "      <td>ReceivesAction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>betrothal</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18438389</th>\n",
       "      <td>uptight</td>\n",
       "      <td>InstanceOf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18444109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AtLocation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             head        relation         tail  score\n",
       "38215         NaN  ReceivesAction       fasten   0.99\n",
       "73145         NaN      InstanceOf     warranty   0.99\n",
       "108082       work  ReceivesAction          NaN   0.99\n",
       "114095        NaN  ReceivesAction         read   0.99\n",
       "124334        NaN  ReceivesAction         lure   0.99\n",
       "...           ...             ...          ...    ...\n",
       "18379073      NaN  ReceivesAction  dereference   0.00\n",
       "18379482     ping  ReceivesAction          NaN   0.00\n",
       "18406398      NaN      InstanceOf    betrothal   0.00\n",
       "18438389  uptight      InstanceOf          NaN   0.00\n",
       "18444109      NaN      AtLocation          NaN   0.00\n",
       "\n",
       "[954 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df[transomcs_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transomcs_df = transomcs_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18480653"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transomcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transomcs_df = transomcs_df[transomcs_df.score >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5534596"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transomcs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transomcs_df.duplicated(subset=['head']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.relation import CONCEPTNET_TO_ATOMIC_MAP, PHYSICAL_RELATIONS, EVENT_RELATIONS, SOCIAL_RELATIONS\n",
    "from collections import defaultdict\n",
    "\n",
    "def relation_to_class(relation):\n",
    "    if relation in PHYSICAL_RELATIONS:\n",
    "        return 0\n",
    "    \n",
    "    if relation in EVENT_RELATIONS:\n",
    "        return 1\n",
    "    \n",
    "    if relation in SOCIAL_RELATIONS:\n",
    "        return 2\n",
    "    \n",
    "    return None\n",
    "\n",
    "test_ood_samples = []\n",
    "unrecognized_rels = set()\n",
    "head_label_map = defaultdict(set)\n",
    "\n",
    "for row in transomcs_df.itertuples():\n",
    "    heads = row.head.split()\n",
    "    if not any([head in train_vocab for head in heads]):\n",
    "        rel_class = relation_to_class(row.relation)\n",
    "        if rel_class is None:\n",
    "            atomic_relations = CONCEPTNET_TO_ATOMIC_MAP.get(row.relation)\n",
    "            if atomic_relations:\n",
    "                if not isinstance(atomic_relations, list):\n",
    "                    atomic_relations = [atomic_relations]\n",
    "                \n",
    "                for rel in atomic_relations:\n",
    "                    rel_class = relation_to_class(rel)\n",
    "                    head_label_map[row.head].add(rel_class)\n",
    "            else:\n",
    "                unrecognized_rels.add(row.relation)\n",
    "        else:\n",
    "            head_label_map[row.head].add(rel_class)\n",
    "\n",
    "for head, labels in head_label_map.items():\n",
    "    final_label = [1 if label in labels else 0 for label in range(3)]\n",
    "    test_ood_samples.append((head, final_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41829"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ood_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CreatedBy', 'InstanceOf'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrecognized_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_df = pd.DataFrame(test_ood_samples, columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>curator</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>foyer</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yolk</td>\n",
       "      <td>[1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fade</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pave</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text      label\n",
       "0  curator  [1, 1, 1]\n",
       "1    foyer  [1, 1, 1]\n",
       "2     yolk  [1, 1, 0]\n",
       "3     fade  [1, 1, 1]\n",
       "4     pave  [1, 1, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ood_df = explode_labels(test_ood_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    41326\n",
       " 0      503\n",
       " Name: label_0, dtype: int64,\n",
       " 1    26603\n",
       " 0    15226\n",
       " Name: label_1, dtype: int64,\n",
       " 0    34929\n",
       " 1     6900\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ood_df.label_0.value_counts(), test_ood_df.label_1.value_counts(), test_ood_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kogito.core.processors.relation import SWEMRelationClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import spacy\n",
    "from relation_modeling_utils import HeadDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "vocab = np.load(\n",
    "    \"./data/vocab_glove_100d.npy\", allow_pickle=True\n",
    ").item()\n",
    "\n",
    "swem_classifier = SWEMRelationClassifier(pooling=\"avg\")\n",
    "swem_classifier.load_state_dict(\n",
    "    torch.load(\n",
    "        \"./models/swem_multi_label_finetune_state_dict.pth\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "swem_test_data = HeadDataset(test_ood_df, vocab=vocab)\n",
    "swem_test_dataloader = DataLoader(swem_test_data, batch_size=len(swem_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    swem_X, swem_y = next(iter(swem_test_dataloader))\n",
    "    swem_preds = swem_classifier.forward(swem_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def report_metrics(preds, y):\n",
    "    test_accuracy = torchmetrics.Accuracy()\n",
    "    test_precision = torchmetrics.Precision(num_classes=3, average=\"weighted\")\n",
    "    test_recall = torchmetrics.Recall(num_classes=3, average=\"weighted\")\n",
    "    test_f1 = torchmetrics.F1Score(num_classes=3, average=\"weighted\")\n",
    "    print(f'Test accuracy={test_accuracy(preds, y).item():.3f}, precision={test_precision(preds, y).item():.3f}, recall={test_recall(preds, y).item():.3f}, f1={test_f1(preds, y).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy=0.628, precision=0.795, recall=0.501, f1=0.587\n"
     ]
    }
   ],
   "source": [
    "report_metrics(swem_preds, swem_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DistilBertHeadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.labels = np.asarray(df['label'].to_list())\n",
    "        self.texts = [self.tokenizer(text, padding='max_length', max_length=32, truncation=True,\n",
    "                                     return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class DistilBERTClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3, dropout=0.5, learning_rate=1e-4, freeze_emb=False):\n",
    "        super().__init__()\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "\n",
    "        if freeze_emb:\n",
    "            for parameter in self.distilbert.parameters():\n",
    "                parameter.requires_grad = False\n",
    "            self.classifier = nn.Sequential(self.linear)\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(self.dropout, self.linear)\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_precision = torchmetrics.Precision(num_classes=3, average='weighted')\n",
    "        self.test_recall = torchmetrics.Recall(num_classes=3, average='weighted')\n",
    "        self.test_f1 = torchmetrics.F1Score(num_classes=3, average='weighted')\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        outputs = self.distilbert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        outputs = self.classifier(outputs[0][:, 0, :])\n",
    "        return outputs\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        mask = X['attention_mask']\n",
    "        input_ids = X['input_ids'].squeeze(1)\n",
    "        outputs = self.forward(input_ids, mask)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        self.test_accuracy(probs, y)\n",
    "        self.test_precision(probs, y)\n",
    "        self.test_recall(probs, y)\n",
    "        self.test_f1(probs, y)\n",
    "        return probs\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        results = dict(accuracy=self.test_accuracy.compute(),\n",
    "                    precision=self.test_precision.compute(),\n",
    "                    recall=self.test_recall.compute(),\n",
    "                    F1=self.test_f1.compute())\n",
    "        self.log_dict(results)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "distilbert_classifier = DistilBERTClassifier.load_from_checkpoint('./models/distilbert/distilbert_model_20220404H1852.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbert_test_data = DistilBertHeadDataset(test_ood_df)\n",
    "dbert_test_dataloader = DataLoader(dbert_test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Missing logger folder: /root/kogito/examples/relation_modeling/lightning_logs\n",
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429211c63b4844e9b2b67cab566f7850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.conda/envs/kogito/lib/python3.8/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': tensor(0.7189, device='cuda:0'), 'precision': tensor(0.8397, device='cuda:0'), 'recall': tensor(0.5454, device='cuda:0'), 'F1': tensor(0.5650, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'F1': 0.5650182366371155,\n",
      " 'accuracy': 0.7189190983772278,\n",
      " 'precision': 0.8396950960159302,\n",
      " 'recall': 0.5454303026199341}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.7189190983772278,\n",
       "  'precision': 0.8396950960159302,\n",
       "  'recall': 0.5454303026199341,\n",
       "  'F1': 0.5650182366371155}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=[0])\n",
    "trainer.test(distilbert_classifier, dbert_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "\n",
    "class BertHeadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.labels = np.asarray(df['label'].to_list())\n",
    "        self.texts = [self.tokenizer(text, padding='max_length', max_length=32, truncation=True,\n",
    "                                     return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class BERTClassifier(pl.LightningModule):\n",
    "    def __init__(self, num_classes=3, dropout=0.5, learning_rate=1e-4, freeze_emb=False):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "\n",
    "        if freeze_emb:\n",
    "            for parameter in self.bert.parameters():\n",
    "                parameter.requires_grad = False\n",
    "            self.classifier = nn.Sequential(self.linear)\n",
    "        else:\n",
    "            self.classifier = nn.Sequential(self.dropout, self.linear)\n",
    "        self.test_accuracy = torchmetrics.Accuracy()\n",
    "        self.test_precision = torchmetrics.Precision(num_classes=3, average='weighted')\n",
    "        self.test_recall = torchmetrics.Recall(num_classes=3, average='weighted')\n",
    "        self.test_f1 = torchmetrics.F1Score(num_classes=3, average='weighted')\n",
    "    \n",
    "    def forward(self, input_ids, mask):\n",
    "        _, outputs = self.bert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        outputs = self.classifier(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        mask = X['attention_mask']\n",
    "        input_ids = X['input_ids'].squeeze(1)\n",
    "        outputs = self.forward(input_ids, mask)\n",
    "        probs = F.sigmoid(outputs)\n",
    "        self.test_accuracy(probs, y)\n",
    "        self.test_precision(probs, y)\n",
    "        self.test_recall(probs, y)\n",
    "        self.test_f1(probs, y)\n",
    "        return probs\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        results = dict(accuracy=self.test_accuracy.compute(),\n",
    "                    precision=self.test_precision.compute(),\n",
    "                    recall=self.test_recall.compute(),\n",
    "                    F1=self.test_f1.compute())\n",
    "        self.log_dict(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_classifier = BERTClassifier.load_from_checkpoint('./models/bert/bert_model_20220404H1850.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_test_data = BertHeadDataset(test_ood_df)\n",
    "bert_test_dataloader = DataLoader(bert_test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_trainer = pl.Trainer(accelerator=\"gpu\", devices=[0])\n",
    "bert_trainer.test(bert_classifier, bert_test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
