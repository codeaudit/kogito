{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import load_data\n",
    "\n",
    "train_df = load_data(\"data/atomic2020_data-feb2021/train.tsv\", multi_label=True)\n",
    "val_df = load_data(\"data/atomic2020_data-feb2021/dev.tsv\", multi_label=True)\n",
    "test_df = load_data(\"data/atomic2020_data-feb2021/test.tsv\", multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36940, 2962, 6569)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abolishes ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abolishes ___ in the states</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abolishes the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text      label\n",
       "0       PersonX abandons ___ altogether  [0, 0, 1]\n",
       "1   PersonX abandons the ___ altogether  [0, 1, 1]\n",
       "2      PersonX abolishes ___ altogether  [0, 1, 1]\n",
       "3   PersonX abolishes ___ in the states  [0, 1, 1]\n",
       "4  PersonX abolishes the ___ altogether  [0, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import explode_labels\n",
    "train_df, test_df = explode_labels(train_df), explode_labels(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    4668\n",
       " 1    1901\n",
       " Name: label_0, dtype: int64,\n",
       " 1    4419\n",
       " 0    2150\n",
       " Name: label_1, dtype: int64,\n",
       " 0    3996\n",
       " 1    2573\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.label_0.value_counts(), test_df.label_1.value_counts(), test_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data lexical overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36940/36940 [00:00<00:00, 172259.68it/s]\n",
      "100%|██████████| 2962/2962 [00:00<00:00, 168591.78it/s]\n",
      "100%|██████████| 6569/6569 [00:00<00:00, 131311.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from relation_modeling_utils import create_vocab\n",
    "train_vocab, val_vocab, test_vocab = create_vocab(train_df), create_vocab(val_df), create_vocab(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical overlap with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27977483705313055, 0.8140804597701149)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_overlap = set(train_vocab).intersection(set(test_vocab))\n",
    "len(train_test_overlap) / len(train_vocab), len(train_test_overlap) / len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1602804661268023, 0.8868852459016393)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_overlap = set(train_vocab).intersection(set(val_vocab))\n",
    "len(train_val_overlap) / len(train_vocab), len(train_val_overlap) / len(val_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical overlap without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36940/36940 [00:00<00:00, 128906.58it/s]\n",
      "100%|██████████| 2962/2962 [00:00<00:00, 156637.27it/s]\n",
      "100%|██████████| 6569/6569 [00:00<00:00, 155559.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "train_vocab_nostp = create_vocab(train_df, include_stopwords=False)\n",
    "val_vocab_nostp = create_vocab(val_df, include_stopwords=False)\n",
    "test_vocab_nostp = create_vocab(test_df, include_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27056102955962197, 0.8061713600958658)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_overlap_nostp = set(train_vocab_nostp).intersection(set(test_vocab_nostp))\n",
    "len(train_test_overlap_nostp) / len(train_vocab_nostp), len(train_test_overlap_nostp) / len(test_vocab_nostp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15041222602051077, 0.8789659224441834)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_overlap_nostp = set(train_vocab_nostp).intersection(set(val_vocab_nostp))\n",
    "len(train_val_overlap_nostp) / len(train_vocab_nostp), len(train_val_overlap_nostp) / len(val_vocab_nostp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new ATOMIC datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "atomic_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43509"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1922"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df.duplicated(subset=[\"text\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import explode_labels\n",
    "atomic_df = explode_labels(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX abolishes ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX abolishes ___ in the states</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX abolishes the ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text      label  label_0  label_1  label_2\n",
       "0       PersonX abandons ___ altogether  [0, 0, 1]        0        0        1\n",
       "1   PersonX abandons the ___ altogether  [0, 1, 1]        0        1        1\n",
       "2      PersonX abolishes ___ altogether  [0, 1, 1]        0        1        1\n",
       "3   PersonX abolishes ___ in the states  [0, 1, 1]        0        1        1\n",
       "4  PersonX abolishes the ___ altogether  [0, 1, 1]        0        1        1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df.duplicated(subset=[\"text\", \"label_0\", \"label_1\", \"label_2\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_df = atomic_df.drop_duplicates(subset=[\"text\", \"label_0\", \"label_1\", \"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_df = atomic_df[atomic_df.duplicated(subset=[\"text\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(duplicated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>PersonX forgets PersonX's lines</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>PersonX forgets PersonX's lines</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text      label  label_0  label_1  label_2\n",
       "5256  PersonX forgets PersonX's lines  [0, 0, 1]        0        0        1\n",
       "3591  PersonX forgets PersonX's lines  [0, 1, 0]        0        1        0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df[atomic_df.text == \"PersonX forgets PersonX's lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>PersonX forgets PersonX's lines</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text      label\n",
       "5256  PersonX forgets PersonX's lines  [0, 0, 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df.text == \"PersonX forgets PersonX's lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>PersonX forgets PersonX's lines</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 text      label\n",
       "3591  PersonX forgets PersonX's lines  [0, 1, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df.text == \"PersonX forgets PersonX's lines\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df.duplicated(subset=[\"text\", \"label_0\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_duplicate_df = atomic_df[atomic_df.duplicated(subset=[\"text\"], keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3514"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_duplicate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PersonX about to get married</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PersonX accepts PersonY thanks</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PersonX accidentally burned</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PersonX accidentally cut</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text      label  label_0  label_1  label_2\n",
       "0   PersonX abandons ___ altogether  [0, 0, 1]        0        0        1\n",
       "5      PersonX about to get married  [0, 0, 1]        0        0        1\n",
       "11   PersonX accepts PersonY thanks  [0, 0, 1]        0        0        1\n",
       "25      PersonX accidentally burned  [0, 0, 1]        0        0        1\n",
       "27         PersonX accidentally cut  [0, 0, 1]        0        0        1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_duplicate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def group_duplicate_heads(subdf):\n",
    "    label_s = np.logical_or(*[np.array(l) for l in subdf.label]).astype(int).tolist()\n",
    "    label0_s = np.logical_or(*subdf.label_0.to_list()).astype(int)\n",
    "    label1_s = np.logical_or(*subdf.label_1.to_list()).astype(int)\n",
    "    label2_s = np.logical_or(*subdf.label_2.to_list()).astype(int)\n",
    "    return pd.Series({\"label\": label_s, \"label_0\": label0_s, \"label_1\": label1_s, \"label_2\": label2_s})\n",
    "\n",
    "handled_dup_df = all_duplicate_df.groupby(\"text\").apply(group_duplicate_heads).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_0</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX about to get married</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PersonX accepts PersonY thanks</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PersonX accidentally burned</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PersonX accidentally cut</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text      label  label_0  label_1  label_2\n",
       "0  PersonX abandons ___ altogether  [0, 1, 1]        0        1        1\n",
       "1     PersonX about to get married  [0, 1, 1]        0        1        1\n",
       "2   PersonX accepts PersonY thanks  [0, 1, 1]        0        1        1\n",
       "3      PersonX accidentally burned  [0, 1, 1]        0        1        1\n",
       "4         PersonX accidentally cut  [0, 1, 1]        0        1        1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handled_dup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43344"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_df = atomic_df.drop_duplicates(subset=[\"text\"], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39830"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_df = pd.concat([atomic_df, handled_dup_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41587"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df.duplicated(subset=[\"text\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create docs out of heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from relation_modeling_utils import IGNORE_WORDS, create_vocab, get_doc\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def make_docs(data, vocab, include_stopwords=True):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "    docs = []\n",
    "\n",
    "    for row in tqdm(data.itertuples(), total=len(data)):\n",
    "        doc = get_doc(nlp, row.text)\n",
    "        words = set()\n",
    "\n",
    "        for token in doc:\n",
    "            if token.text not in IGNORE_WORDS and (include_stopwords or token.text not in STOP_WORDS):\n",
    "                words.add(token.lemma_)\n",
    "        \n",
    "        doc.user_data['words'] = words\n",
    "        doc.user_data['label'] = row.label\n",
    "        docs.append(doc)\n",
    "    \n",
    "    for doc in docs:\n",
    "        freqs = 0\n",
    "\n",
    "        for word in doc.user_data['words']:\n",
    "            freqs += max(vocab.get(word, 0) - 1, 0)\n",
    "        \n",
    "        doc.user_data['relative_freq'] = freqs\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41587/41587 [00:00<00:00, 166489.15it/s]\n"
     ]
    }
   ],
   "source": [
    "atomic_vocab = create_vocab(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41587/41587 [00:00<00:00, 105698.05it/s]\n"
     ]
    }
   ],
   "source": [
    "atomic_docs = make_docs(atomic_df, atomic_vocab, include_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 1440), ('a', 2819), ('to', 2948), ('the', 4474), (\"'s\", 6003)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(atomic_vocab.items(), key=lambda i: i[1])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_docs = [doc for doc in atomic_docs if doc.user_data['label'][0] == 1]\n",
    "class2_docs = [doc for doc in atomic_docs if doc.user_data['label'][1] == 1]\n",
    "class3_docs = [doc for doc in atomic_docs if doc.user_data['label'][2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQUENCY_THRESHOLD = 5\n",
    "class1_freq1_docs = [doc for doc in class1_docs if doc.user_data['relative_freq'] < 1][:500]\n",
    "class2_freq1_docs = [doc for doc in class2_docs if doc.user_data['relative_freq'] < FREQUENCY_THRESHOLD][:500]\n",
    "class3_freq1_docs = [doc for doc in class3_docs if doc.user_data['relative_freq'] < FREQUENCY_THRESHOLD][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 500)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class1_freq1_docs), len(class2_freq1_docs), len(class3_freq1_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = [doc.text for doc in class1_freq1_docs+class2_freq1_docs+class3_freq1_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data, new_test_data = [], []\n",
    "\n",
    "for row in atomic_df.itertuples():\n",
    "    if row.text in test_samples:\n",
    "        new_test_data.append((row.text, row.label))\n",
    "    else:\n",
    "        new_train_data.append((row.text, row.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = pd.DataFrame(new_train_data, columns=[\"text\", \"label\"])\n",
    "new_test_df = pd.DataFrame(new_test_data, columns=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40395, 1192)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_df), len(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40395/40395 [00:00<00:00, 177888.02it/s]\n",
      "100%|██████████| 1192/1192 [00:00<00:00, 238827.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from relation_modeling_utils import create_vocab\n",
    "new_train_vocab, new_test_vocab = create_vocab(new_train_df), create_vocab(new_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New lexical overlap with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04423538831064852, 0.36140637775960754)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_test_overlap = set(new_train_vocab).intersection(set(new_test_vocab))\n",
    "len(new_train_test_overlap) / len(new_train_vocab), len(new_train_test_overlap) / len(new_test_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New lexical overlap without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40395/40395 [00:00<00:00, 116597.84it/s]\n",
      "100%|██████████| 1192/1192 [00:00<00:00, 225359.94it/s]\n"
     ]
    }
   ],
   "source": [
    "new_train_vocab_nostp = create_vocab(new_train_df, include_stopwords=False)\n",
    "new_test_vocab_nostp = create_vocab(new_test_df, include_stopwords=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.034236804564907276, 0.30134529147982064)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_test_overlap_nostp = set(new_train_vocab_nostp).intersection(set(new_test_vocab_nostp))\n",
    "len(new_train_test_overlap_nostp) / len(new_train_vocab_nostp), len(new_train_test_overlap_nostp) / len(new_test_vocab_nostp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import explode_labels\n",
    "new_train_df, new_test_df = explode_labels(new_train_df), explode_labels(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    623\n",
       " 1    569\n",
       " Name: label_0, dtype: int64,\n",
       " 0    692\n",
       " 1    500\n",
       " Name: label_1, dtype: int64,\n",
       " 0    654\n",
       " 1    538\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df.label_0.value_counts(), new_test_df.label_1.value_counts(), new_test_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('class_0', 0): 0.48237476808905383,\n",
       " ('class_0', 'class_0', 0, 0): 0.48237476808905383,\n",
       " ('class_0', 'class_0', 0, 1): 0.0,\n",
       " ('class_0', 1): 0.5176252319109462,\n",
       " ('class_0', 'class_0', 1, 0): 0.0,\n",
       " ('class_0', 'class_0', 1, 1): 0.5176252319109462,\n",
       " ('class_0', 'class_1', 0, 0): 0.19851576994434136,\n",
       " ('class_0', 'class_1', 0, 1): 0.28385899814471244,\n",
       " ('class_0', 'class_1', 1, 0): 0.45732838589981445,\n",
       " ('class_0', 'class_1', 1, 1): 0.06029684601113173,\n",
       " ('class_0', 'class_2', 0, 0): 0.07792207792207792,\n",
       " ('class_0', 'class_2', 0, 1): 0.4044526901669759,\n",
       " ('class_0', 'class_2', 1, 0): 0.5111317254174397,\n",
       " ('class_0', 'class_2', 1, 1): 0.006493506493506494,\n",
       " ('class_1', 0): 0.6558441558441559,\n",
       " ('class_1', 'class_0', 0, 0): 0.19851576994434136,\n",
       " ('class_1', 'class_0', 0, 1): 0.45732838589981445,\n",
       " ('class_1', 1): 0.34415584415584416,\n",
       " ('class_1', 'class_0', 1, 0): 0.28385899814471244,\n",
       " ('class_1', 'class_0', 1, 1): 0.06029684601113173,\n",
       " ('class_1', 'class_1', 0, 0): 0.6558441558441559,\n",
       " ('class_1', 'class_1', 0, 1): 0.0,\n",
       " ('class_1', 'class_1', 1, 0): 0.0,\n",
       " ('class_1', 'class_1', 1, 1): 0.34415584415584416,\n",
       " ('class_1', 'class_2', 0, 0): 0.4536178107606679,\n",
       " ('class_1', 'class_2', 0, 1): 0.20222634508348794,\n",
       " ('class_1', 'class_2', 1, 0): 0.13543599257884972,\n",
       " ('class_1', 'class_2', 1, 1): 0.20871985157699444,\n",
       " ('class_2', 0): 0.5890538033395176,\n",
       " ('class_2', 'class_0', 0, 0): 0.07792207792207792,\n",
       " ('class_2', 'class_0', 0, 1): 0.5111317254174397,\n",
       " ('class_2', 1): 0.4109461966604824,\n",
       " ('class_2', 'class_0', 1, 0): 0.4044526901669759,\n",
       " ('class_2', 'class_0', 1, 1): 0.006493506493506494,\n",
       " ('class_2', 'class_1', 0, 0): 0.4536178107606679,\n",
       " ('class_2', 'class_1', 0, 1): 0.13543599257884972,\n",
       " ('class_2', 'class_1', 1, 0): 0.20222634508348794,\n",
       " ('class_2', 'class_1', 1, 1): 0.20871985157699444,\n",
       " ('class_2', 'class_2', 0, 0): 0.5890538033395176,\n",
       " ('class_2', 'class_2', 0, 1): 0.0,\n",
       " ('class_2', 'class_2', 1, 0): 0.0,\n",
       " ('class_2', 'class_2', 1, 1): 0.4109461966604824}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relation_modeling_utils import get_class_dist_report\n",
    "\n",
    "get_class_dist_report(new_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.to_csv(\"data/atomic_ood2/n5/train_n5.csv\")\n",
    "new_test_df.to_csv(\"data/atomic_ood2/n5/test_n5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import load_fdata, create_vocab\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def get_vocab_info(dataset_type):\n",
    "    train_f = load_fdata(f\"data/atomic_ood2/{dataset_type}/train_{dataset_type}.csv\")\n",
    "    test_f = load_fdata(f\"data/atomic_ood2/{dataset_type}/test_{dataset_type}.csv\")\n",
    "    train_f_vocab, test_f_vocab = create_vocab(train_f), create_vocab(test_f)\n",
    "    train_f_nostp, test_f_nostp = create_vocab(train_f,include_stopwords=False), create_vocab(test_f, include_stopwords=False)\n",
    "    return {\n",
    "        'train': len(train_f_vocab), 'test': len(test_f_vocab),\n",
    "        'train_nostp': len(train_f_nostp), 'test_nostp': len(test_f_nostp)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40777/40777 [00:00<00:00, 193758.42it/s]\n",
      "100%|██████████| 810/810 [00:00<00:00, 206779.44it/s]\n",
      "100%|██████████| 40777/40777 [00:00<00:00, 164638.55it/s]\n",
      "100%|██████████| 810/810 [00:00<00:00, 244662.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 10036, 'test': 825, 'train_nostp': 9857, 'test_nostp': 736}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocab_info(\"n1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150325/150325 [00:00<00:00, 702886.36it/s]\n",
      "100%|██████████| 16539/16539 [00:00<00:00, 972093.91it/s]\n",
      "100%|██████████| 2561/2561 [00:00<00:00, 785263.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': 9706,\n",
       " 'val': 2933,\n",
       " 'test': 1096,\n",
       " 'train_nostp': 9488,\n",
       " 'val_nostp': 2775,\n",
       " 'test_nostp': 996}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocab_info(\"n3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vocab_info(\"n5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
