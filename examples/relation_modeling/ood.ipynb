{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import load_data\n",
    "\n",
    "train_df = load_data(\"data/atomic2020_data-feb2021/train.tsv\", multi_label=True)\n",
    "val_df = load_data(\"data/atomic2020_data-feb2021/dev.tsv\", multi_label=True)\n",
    "test_df = load_data(\"data/atomic2020_data-feb2021/test.tsv\", multi_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36940, 2962, 6569)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data lexical overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140049/140049 [00:00<00:00, 903496.24it/s]\n",
      "100%|██████████| 14524/14524 [00:00<00:00, 940616.26it/s]\n",
      "100%|██████████| 27270/27270 [00:00<00:00, 892746.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from relation_modeling_utils import create_vocab\n",
    "train_vocab, val_vocab, test_vocab = create_vocab(train_df), create_vocab(val_df), create_vocab(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical overlap with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2782412405535381, 0.8130197877831947)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_overlap = set(train_vocab).intersection(set(test_vocab))\n",
    "len(train_test_overlap) / len(train_vocab), len(train_test_overlap) / len(test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15889684954362548, 0.8837336244541485)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_overlap = set(train_vocab).intersection(set(val_vocab))\n",
    "len(train_val_overlap) / len(train_vocab), len(train_val_overlap) / len(val_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical overlap without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "train_vocab_nostp = {word: freq for word, freq in train_vocab.items() if word not in STOP_WORDS}\n",
    "val_vocab_nostp = {word: freq for word, freq in val_vocab.items() if word not in STOP_WORDS}\n",
    "test_vocab_nostp = {word: freq for word, freq in test_vocab.items() if word not in STOP_WORDS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.26732176877569436, 0.8037383177570093)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_overlap_nostp = set(train_vocab_nostp).intersection(set(test_vocab_nostp))\n",
    "len(train_test_overlap_nostp) / len(train_vocab_nostp), len(train_test_overlap_nostp) / len(test_vocab_nostp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14739797453123432, 0.8739595719381689)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_overlap_nostp = set(train_vocab_nostp).intersection(set(val_vocab_nostp))\n",
    "len(train_val_overlap_nostp) / len(train_vocab_nostp), len(train_val_overlap_nostp) / len(val_vocab_nostp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new ATOMIC datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "atomic_df = pd.concat([train_df, val_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46471"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2513"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_df.duplicated(subset=[\"text\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_df = atomic_df.drop_duplicates(subset=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43958"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from relation_modeling_utils import IGNORE_WORDS, create_vocab\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def make_docs(data, vocab, exclude_stopwords=False):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])\n",
    "    docs = []\n",
    "\n",
    "    for row in tqdm(data.itertuples(), total=len(data)):\n",
    "        doc = nlp(row.text)\n",
    "        words = set()\n",
    "\n",
    "        for token in doc:\n",
    "            if token.text not in IGNORE_WORDS and (not exclude_stopwords or token.text not in STOP_WORDS):\n",
    "                words.add(token.lemma_)\n",
    "        \n",
    "        doc.user_data['words'] = words\n",
    "        doc.user_data['label'] = row.label\n",
    "        docs.append(doc)\n",
    "    \n",
    "    for doc in docs:\n",
    "        freqs = 0\n",
    "        for word in doc.user_data['words']:\n",
    "            freqs += vocab.get(word, 0) - 1\n",
    "        \n",
    "        doc.user_data['relative_freq'] = freqs\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169425/169425 [00:00<00:00, 911559.59it/s]\n"
     ]
    }
   ],
   "source": [
    "atomic_vocab = create_vocab(atomic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43958/43958 [02:45<00:00, 266.21it/s]\n"
     ]
    }
   ],
   "source": [
    "atomic_docs = make_docs(atomic_df, atomic_vocab, exclude_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 1555), ('a', 3031), ('to', 3141), ('the', 4831), (\"'s\", 6519)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(atomic_vocab.items(), key=lambda i: i[1])[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_docs = [doc for doc in atomic_docs if doc.user_data['label'][0] == 1]\n",
    "class2_docs = [doc for doc in atomic_docs if doc.user_data['label'][1] == 1]\n",
    "class3_docs = [doc for doc in atomic_docs if doc.user_data['label'][2] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQUENCY_THRESHOLD = 1\n",
    "class1_freq1_docs = [doc for doc in class1_docs if doc.user_data['relative_freq'] < 1][:500]\n",
    "class2_freq1_docs = [doc for doc in class2_docs if doc.user_data['relative_freq'] < FREQUENCY_THRESHOLD][:1000]\n",
    "class3_freq1_docs = [doc for doc in class3_docs if doc.user_data['relative_freq'] < FREQUENCY_THRESHOLD][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 213, 241)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class1_freq1_docs), len(class2_freq1_docs), len(class3_freq1_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = [doc.text for doc in class1_freq1_docs+class2_freq1_docs+class3_freq1_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data, new_test_data = [], []\n",
    "\n",
    "for row in atomic_df.itertuples():\n",
    "    if row.text in test_samples:\n",
    "        new_test_data.append((row.text, row.label))\n",
    "    else:\n",
    "        new_train_data.append((row.text, row.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_train_df, new_val_df = train_test_split(pd.DataFrame(new_train_data, columns=[\"text\", \"label\"]), test_size=0.1, random_state=42)\n",
    "new_test_df = pd.DataFrame(new_test_data, columns=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38822, 4314, 822)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_df), len(new_val_df), len(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151030/151030 [00:00<00:00, 665154.35it/s]\n",
      "100%|██████████| 16802/16802 [00:00<00:00, 756469.47it/s]\n",
      "100%|██████████| 1593/1593 [00:00<00:00, 655244.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from relation_modeling_utils import create_vocab\n",
    "new_train_vocab, new_val_vocab, new_test_vocab = create_vocab(new_train_df), create_vocab(new_val_df), create_vocab(new_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New lexical overlap with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24600900532132625, 0.8215994531784006)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_val_overlap = set(new_train_vocab).intersection(set(new_val_vocab))\n",
    "len(new_train_val_overlap) / len(new_train_vocab), len(new_train_val_overlap) / len(new_val_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.010233319688907082, 0.12004801920768307)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_test_overlap = set(new_train_vocab).intersection(set(new_test_vocab))\n",
    "len(new_train_test_overlap) / len(new_train_vocab), len(new_train_test_overlap) / len(new_test_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New lexical overlap without stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_vocab_nostp = {word: freq for word, freq in new_train_vocab.items() if word not in STOP_WORDS}\n",
    "new_val_vocab_nostp = {word: freq for word, freq in new_val_vocab.items() if word not in STOP_WORDS}\n",
    "new_test_vocab_nostp = {word: freq for word, freq in new_test_vocab.items() if word not in STOP_WORDS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23518944944525852, 0.8114842903575298)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_val_overlap_nostp = set(new_train_vocab_nostp).intersection(set(new_val_vocab_nostp))\n",
    "len(new_train_val_overlap_nostp) / len(new_train_vocab_nostp), len(new_train_val_overlap_nostp) / len(new_val_vocab_nostp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0015700230270043961, 0.020053475935828877)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_test_overlap_nostp = set(new_train_vocab_nostp).intersection(set(new_test_vocab_nostp))\n",
    "len(new_train_test_overlap_nostp) / len(new_train_vocab_nostp), len(new_train_test_overlap_nostp) / len(new_test_vocab_nostp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relation_modeling_utils import explode_labels\n",
    "new_train_df, new_val_df, new_test_df = explode_labels(new_train_df), explode_labels(new_val_df), explode_labels(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    2729\n",
       " 1    1585\n",
       " Name: label_0, dtype: int64,\n",
       " 1    2261\n",
       " 0    2053\n",
       " Name: label_1, dtype: int64,\n",
       " 1    2557\n",
       " 0    1757\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_val_df.label_0.value_counts(), new_val_df.label_1.value_counts(), new_val_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1    526\n",
       " 0    296\n",
       " Name: label_0, dtype: int64,\n",
       " 0    609\n",
       " 1    213\n",
       " Name: label_1, dtype: int64,\n",
       " 0    581\n",
       " 1    241\n",
       " Name: label_2, dtype: int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_df.label_0.value_counts(), new_test_df.label_1.value_counts(), new_test_df.label_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('class_0', 0): 0.48237476808905383,\n",
       " ('class_0', 'class_0', 0, 0): 0.48237476808905383,\n",
       " ('class_0', 'class_0', 0, 1): 0.0,\n",
       " ('class_0', 1): 0.5176252319109462,\n",
       " ('class_0', 'class_0', 1, 0): 0.0,\n",
       " ('class_0', 'class_0', 1, 1): 0.5176252319109462,\n",
       " ('class_0', 'class_1', 0, 0): 0.19851576994434136,\n",
       " ('class_0', 'class_1', 0, 1): 0.28385899814471244,\n",
       " ('class_0', 'class_1', 1, 0): 0.45732838589981445,\n",
       " ('class_0', 'class_1', 1, 1): 0.06029684601113173,\n",
       " ('class_0', 'class_2', 0, 0): 0.07792207792207792,\n",
       " ('class_0', 'class_2', 0, 1): 0.4044526901669759,\n",
       " ('class_0', 'class_2', 1, 0): 0.5111317254174397,\n",
       " ('class_0', 'class_2', 1, 1): 0.006493506493506494,\n",
       " ('class_1', 0): 0.6558441558441559,\n",
       " ('class_1', 'class_0', 0, 0): 0.19851576994434136,\n",
       " ('class_1', 'class_0', 0, 1): 0.45732838589981445,\n",
       " ('class_1', 1): 0.34415584415584416,\n",
       " ('class_1', 'class_0', 1, 0): 0.28385899814471244,\n",
       " ('class_1', 'class_0', 1, 1): 0.06029684601113173,\n",
       " ('class_1', 'class_1', 0, 0): 0.6558441558441559,\n",
       " ('class_1', 'class_1', 0, 1): 0.0,\n",
       " ('class_1', 'class_1', 1, 0): 0.0,\n",
       " ('class_1', 'class_1', 1, 1): 0.34415584415584416,\n",
       " ('class_1', 'class_2', 0, 0): 0.4536178107606679,\n",
       " ('class_1', 'class_2', 0, 1): 0.20222634508348794,\n",
       " ('class_1', 'class_2', 1, 0): 0.13543599257884972,\n",
       " ('class_1', 'class_2', 1, 1): 0.20871985157699444,\n",
       " ('class_2', 0): 0.5890538033395176,\n",
       " ('class_2', 'class_0', 0, 0): 0.07792207792207792,\n",
       " ('class_2', 'class_0', 0, 1): 0.5111317254174397,\n",
       " ('class_2', 1): 0.4109461966604824,\n",
       " ('class_2', 'class_0', 1, 0): 0.4044526901669759,\n",
       " ('class_2', 'class_0', 1, 1): 0.006493506493506494,\n",
       " ('class_2', 'class_1', 0, 0): 0.4536178107606679,\n",
       " ('class_2', 'class_1', 0, 1): 0.13543599257884972,\n",
       " ('class_2', 'class_1', 1, 0): 0.20222634508348794,\n",
       " ('class_2', 'class_1', 1, 1): 0.20871985157699444,\n",
       " ('class_2', 'class_2', 0, 0): 0.5890538033395176,\n",
       " ('class_2', 'class_2', 0, 1): 0.0,\n",
       " ('class_2', 'class_2', 1, 0): 0.0,\n",
       " ('class_2', 'class_2', 1, 1): 0.4109461966604824}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from relation_modeling_utils import get_class_dist_report\n",
    "\n",
    "get_class_dist_report(new_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df.to_csv(\"data/atomic_ood/f1/train_f1.csv\")\n",
    "new_val_df.to_csv(\"data/atomic_ood/f1/val_f1.csv\")\n",
    "new_test_df.to_csv(\"data/atomic_ood/f1/test_f1.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
