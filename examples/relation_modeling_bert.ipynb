{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[[  101, 19783,  3190,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[  101, 19783,  3190,  ...,     0,     0,     0]]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]]])}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "import wandb\n",
    "\n",
    "\n",
    "class HeadDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "        self.labels = df['label'].to_numpy()\n",
    "        self.texts = [self.tokenizer(text, padding='max_length', max_length=512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5, hidden_dim=768, num_classes=3):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, mask):\n",
    "        _, outputs = self.bert(input_ids=input_ids, attention_mask=mask, return_dict=False)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.linear(outputs)\n",
    "        probs = self.softmax(outputs)\n",
    "\n",
    "        return probs\n",
    "    \n",
    "    def save_pretrained(self, path):\n",
    "        torch.save(self, path)\n",
    "\n",
    "\n",
    "def train(model, train_dataset, val_dataset, learning_rate=1e-3, epochs=10, batch_size=8):\n",
    "    # wandb.init(project=\"kogito-relation-matcher\", config={\"learning_rate\": learning_rate, \"epochs\": epochs, \"batch_size\": batch_size})\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        print(\"Using CUDA\")\n",
    "        model = model.to(device)\n",
    "        criterion = criterion.to(device)\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            model.zero_grad()\n",
    "\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_ids = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_ids, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_ids = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_ids, mask)\n",
    "\n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "        \n",
    "        train_loss = total_loss_train / len(train_data)\n",
    "        train_acc = total_acc_train / len(train_data)\n",
    "        val_loss = total_loss_val / len(val_data)\n",
    "        val_acc = total_acc_val / len(val_data)\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Train Loss: {train_loss: .3f} \\\n",
    "            | Train Accuracy: {train_acc: .3f} \\\n",
    "            | Val Loss: {val_loss: .3f} \\\n",
    "            | Val Accuracy: {val_acc: .3f}')\n",
    "        \n",
    "        # wandb.log({\"train_loss\": train_loss, \"train_accuracy\": train_acc, \"val_loss\": val_loss, \"val_accuracy\": val_acc})\n",
    "        model.save_pretrained(f\"./models/checkpoint_{epoch_num}.pth\")\n",
    "\n",
    "\n",
    "from relation_modeling_utils import load_data\n",
    "\n",
    "train_df = load_data(\"data/atomic2020_data-feb2021/train.tsv\")\n",
    "dev_df = load_data(\"data/atomic2020_data-feb2021/dev.tsv\")\n",
    "train_data = HeadDataset(train_df)\n",
    "val_data = HeadDataset(dev_df)\n",
    "# model = BertClassifier()\n",
    "# train(model=model, train_dataset=train_data, val_dataset=val_data, epochs=2, batch_size=2)\n",
    "# model.save_pretrained(\"./models/final_model.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 512]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "\n",
    "for train_input, train_label in train_dataloader:\n",
    "    print(train_input[\"input_ids\"].shape, train_label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'input_ids': tensor([[  101, 19783,  3190, 11092,  1116,   168,   168,   168, 11257,   102,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0]])},\n",
       "  {'input_ids': tensor([[  101, 19783,  3190, 11092,  1116,  1103,   168,   168,   168, 11257,\n",
       "             102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0]])}],\n",
       " array([2, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:2]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c3b128559c7e8fd624042ca8b6c93b33cd59aca7b58d05c9d4cd21ec1a84d35"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
