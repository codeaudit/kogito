{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cc_news = load_dataset(\"cc_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(cc_news[\"train\"], shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(loader))\n",
    "\n",
    "len(samples[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cc_news_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in samples[\"description\"] if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dialog = load_dataset(\"daily_dialog\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(daily_dialog, shuffle=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dialog[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_samples = [\"\".join(dialog) for dialog in daily_dialog[:50][\"dialog\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dialog_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dialog_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in dialog_samples if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_stories = load_dataset(\"wza/roc_stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_samples = roc_stories[\"train\"][:50]\n",
    "roc_samples = [\" \".join(sample) for sample in zip(roc_samples[\"sentence1\"], roc_samples[\"sentence2\"], roc_samples[\"sentence3\"], roc_samples[\"sentence4\"], roc_samples[\"sentence5\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_samples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/story_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in roc_samples if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"PersonX falls in love with PersonY\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\", short conversation   \".strip(string.punctuation+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.processors.head import NounPhraseHeadExtractor, VerbPhraseHeadExtractor\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ext = NounPhraseHeadExtractor(\"ext\", nlp)\n",
    "vext = VerbPhraseHeadExtractor(\"vext\", nlp)\n",
    "ext.extract(\"April 24 (Reuters) - Borrowing by U.S. businesses for capital goods rose 2 percent in March from a year earlier, the Equipment Leasing and Finance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "\n",
    "# Initialize inference module with a spacy language pipeline\n",
    "csi = CommonsenseInference(language=\"en_core_web_sm\")\n",
    "\n",
    "# Run inference\n",
    "text = \"the researcher\"\n",
    "csi.remove_processor(\"noun_phrase_extractor\")\n",
    "csi.remove_processor(\"verb_phrase_extractor\")\n",
    "csi.remove_processor(\"sentence_extractor\")\n",
    "kgraph = csi.infer(text, extract_heads=True)\n",
    "print(kgraph)\n",
    "# Save output knowledge graph to JSON file\n",
    "# kgraph.to_jsonl(\"results/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3.zeroshot import GPT3Zeroshot\n",
    "from kogito.core.relation import KnowledgeRelation, register_relation, EVENT_RELATIONS\n",
    "import time, os\n",
    "\n",
    "# csi = CommonsenseInference()\n",
    "# csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "def x_wishes_verbalizer(head, **kwargs):\n",
    "   # index will be passed from the model\n",
    "   # so that we can enumerate samples which helps with inference\n",
    "   index = kwargs.get(\"index\")\n",
    "   index_txt = f\"{index}\" if index is not None else \"\"\n",
    "   return f\"Situation {index_txt}: {head}\\nWishes: As a result, PersonX wishes\"\n",
    "\n",
    "X_WISHES = KnowledgeRelation(\"xWishes\",\n",
    "                             verbalizer=x_wishes_verbalizer,\n",
    "                             prompt=\"How does this situation affect each character's wishes?\")\n",
    "register_relation(X_WISHES, kind=\"social\")\n",
    "print(X_WISHES in EVENT_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.knowledge import Knowledge, KnowledgeGraph\n",
    "\n",
    "kg1 = Knowledge(\"h1\", \"xWants\", [\"hi\", \"\", \"  \"])\n",
    "kg2 = Knowledge(\"h2\", \"xWants\", [\"hi\", \"ho\", \" hah \"])\n",
    "kg3 = Knowledge(\"h3\", \"xWants\", [\"hi\", \"\", \" huha \"])\n",
    "kg4 = Knowledge(\"h4\", \"xWants\", [\"\", \" \", \"  \"])\n",
    "\n",
    "kgraph = KnowledgeGraph([kg1, kg2, kg3, kg4])\n",
    "print(kgraph)\n",
    "kgraph.clean()\n",
    "print(kgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.utils import SortishSampler\n",
    "\n",
    "ss = SortishSampler(list(range(100)), 16)\n",
    "\n",
    "for s in ss:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "print(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "extractor = pipeline(\"feature-extraction\", model=\"bert-base-uncased\")\n",
    "output = extractor(\"Hello world\", return_tensors=\"pt\")\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertLMHeadModel\n",
    "\n",
    "bert = BertLMHeadModel.from_pretrained(\"bert-base-uncased\")\n",
    "print(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "bart = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "print(bart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kogito.core.knowledge import KnowledgeGraph, Knowledge\n",
    "import pandas as pd\n",
    "\n",
    "train_graph = KnowledgeGraph.from_csv(\n",
    "    \"data/atomic2020/sample.tsv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>head</td>\n",
       "      <td>relation</td>\n",
       "      <td>tails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PersonX abandons ___ altogether</td>\n",
       "      <td>oEffect</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0         1      2\n",
       "0                             head  relation  tails\n",
       "1  PersonX abandons ___ altogether   oEffect   none"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/atomic2020/sample.tsv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Knowledge(head=\"PersonX abandons ___ altogether\", relation=\"oEffect\", tails=['none'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_graph[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kogito-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f24965dd94e4c0052d788733e7ddbb6e931f72d604403246d6e227e2d7fe7557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
