{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.38k/4.38k [00:00<00:00, 936kB/s]\n",
      "Downloading metadata: 100%|██████████| 2.04k/2.04k [00:00<00:00, 896kB/s]\n",
      "Downloading readme: 100%|██████████| 7.46k/7.46k [00:00<00:00, 2.69MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cc_news/plain_text to /Users/mismayil/.cache/huggingface/datasets/cc_news/plain_text/1.0.0/ae469e556251e6e7e20a789f93803c7de19d0c4311b6854ab072fecb4e401bd6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 845M/845M [00:41<00:00, 20.3MB/s] \n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cc_news downloaded and prepared to /Users/mismayil/.cache/huggingface/datasets/cc_news/plain_text/1.0.0/ae469e556251e6e7e20a789f93803c7de19d0c4311b6854ab072fecb4e401bd6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cc_news = load_dataset(\"cc_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(cc_news[\"train\"], shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = next(iter(loader))\n",
    "\n",
    "len(samples[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cc_news_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in samples[\"description\"] if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.85k/4.85k [00:00<00:00, 1.84MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.49k/2.49k [00:00<00:00, 1.14MB/s]\n",
      "Downloading readme: 100%|██████████| 7.21k/7.21k [00:00<00:00, 2.31MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset daily_dialog/default to /Users/mismayil/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 4.48M/4.48M [00:01<00:00, 3.69MB/s]\n",
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset daily_dialog downloaded and prepared to /Users/mismayil/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "daily_dialog = load_dataset(\"daily_dialog\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialog', 'act', 'emotion'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(daily_dialog, shuffle=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog': [['Hey man , you wanna buy some weed ? ',\n",
       "   ' Some what ? ',\n",
       "   ' Weed ! You know ? Pot , Ganja , Mary Jane some chronic ! ',\n",
       "   ' Oh , umm , no thanks . ',\n",
       "   ' I also have blow if you prefer to do a few lines . ',\n",
       "   ' No , I am ok , really . ',\n",
       "   ' Come on man ! I even got dope and acid ! Try some ! ',\n",
       "   ' Do you really have all of these drugs ? Where do you get them from ? ',\n",
       "   ' I got my connections ! Just tell me what you want and I ’ ll even give you one ounce for free . ',\n",
       "   ' Sounds good ! Let ’ s see , I want . ',\n",
       "   ' Yeah ? ',\n",
       "   ' I want you to put your hands behind your head ! You are under arrest ! '],\n",
       "  ['The taxi drivers are on strike again . ',\n",
       "   ' What for ? ',\n",
       "   ' They want the government to reduce the price of the gasoline . ',\n",
       "   ' It is really a hot potato . ']],\n",
       " 'act': [[3, 2, 3, 4, 3, 4, 3, 2, 3, 4, 2, 3], [1, 2, 1, 1]],\n",
       " 'emotion': [[0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0], [0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_dialog[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_samples = [\"\".join(dialog) for dialog in daily_dialog[:50][\"dialog\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dialog_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dialog_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in dialog_samples if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.51k/6.51k [00:00<00:00, 2.33MB/s]\n",
      "Downloading metadata: 100%|██████████| 1.33k/1.33k [00:00<00:00, 459kB/s]\n",
      "No config specified, defaulting to: roc_stories/all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset roc_stories/all to /Users/mismayil/.cache/huggingface/datasets/wza___roc_stories/all/2.1.0/43e2851d9f31e08e4b2dd07a8057ed7a64cbb25cc7105d09856c14e638695506...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 13.1M/13.1M [00:01<00:00, 10.8MB/s]\n",
      "Downloading data: 100%|██████████| 14.5M/14.5M [00:01<00:00, 11.8MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 320.00it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset roc_stories downloaded and prepared to /Users/mismayil/.cache/huggingface/datasets/wza___roc_stories/all/2.1.0/43e2851d9f31e08e4b2dd07a8057ed7a64cbb25cc7105d09856c14e638695506. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 113.57it/s]\n"
     ]
    }
   ],
   "source": [
    "roc_stories = load_dataset(\"wza/roc_stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['storyid', 'storytitle', 'sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5'],\n",
       "        num_rows: 98161\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_samples = roc_stories[\"train\"][:50]\n",
    "roc_samples = [\" \".join(sample) for sample in zip(roc_samples[\"sentence1\"], roc_samples[\"sentence2\"], roc_samples[\"sentence3\"], roc_samples[\"sentence4\"], roc_samples[\"sentence5\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Dan's parents were overweight. Dan was overweight as well. The doctors told his parents it was unhealthy. His parents understood and decided to make a change. They got themselves and Dan on a diet.\",\n",
       " \"Carrie had just learned how to ride a bike. She didn't have a bike of her own. Carrie would sneak rides on her sister's bike. She got nervous on a hill and crashed into a wall. The bike frame bent and Carrie got a deep gash on her leg.\",\n",
       " \"Morgan enjoyed long walks on the beach. She and her boyfriend decided to go for a long walk. After walking for over a mile, something happened. Morgan decided to propose to her boyfriend. Her boyfriend was upset he didn't propose to her first.\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_samples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/story_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in roc_samples if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonX nsubj []\n",
      "falls ROOT [PersonX, in, with]\n",
      "in prep [love]\n",
      "love pobj []\n",
      "with prep [PersonY]\n",
      "PersonY pobj []\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"PersonX falls in love with PersonY\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'short conversation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\", short conversation   \".strip(string.punctuation+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Borrowing,\n",
       " businesses,\n",
       " capital,\n",
       " goods,\n",
       " percent,\n",
       " year,\n",
       " Reuters,\n",
       " U.S. businesses,\n",
       " capital goods,\n",
       " March]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kogito.core.processors.head import NounPhraseHeadExtractor, VerbPhraseHeadExtractor\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ext = NounPhraseHeadExtractor(\"ext\", nlp)\n",
    "vext = VerbPhraseHeadExtractor(\"vext\", nlp)\n",
    "ext.extract(\"April 24 (Reuters) - Borrowing by U.S. businesses for capital goods rose 2 percent in March from a year earlier, the Equipment Leasing and Finance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/Desktop/EPFL/nlplab/kogito/kogito/inference.py:168: UserWarning: Skipping inference, no heads found.\n",
      "  warnings.warn(\"Skipping inference, no heads found.\")\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "\n",
    "# Initialize inference module with a spacy language pipeline\n",
    "csi = CommonsenseInference(language=\"en_core_web_sm\")\n",
    "\n",
    "# Run inference\n",
    "text = \"the researcher\"\n",
    "csi.remove_processor(\"noun_phrase_extractor\")\n",
    "csi.remove_processor(\"verb_phrase_extractor\")\n",
    "csi.remove_processor(\"sentence_extractor\")\n",
    "kgraph = csi.infer(text, extract_heads=True)\n",
    "print(kgraph)\n",
    "# Save output knowledge graph to JSON file\n",
    "# kgraph.to_jsonl(\"results/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3.zeroshot import GPT3Zeroshot\n",
    "from kogito.core.relation import KnowledgeRelation, register_relation, EVENT_RELATIONS\n",
    "import time, os\n",
    "\n",
    "# csi = CommonsenseInference()\n",
    "# csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "def x_wishes_verbalizer(head, **kwargs):\n",
    "   # index will be passed from the model\n",
    "   # so that we can enumerate samples which helps with inference\n",
    "   index = kwargs.get(\"index\")\n",
    "   index_txt = f\"{index}\" if index is not None else \"\"\n",
    "   return f\"Situation {index_txt}: {head}\\nWishes: As a result, PersonX wishes\"\n",
    "\n",
    "X_WISHES = KnowledgeRelation(\"xWishes\",\n",
    "                             verbalizer=x_wishes_verbalizer,\n",
    "                             prompt=\"How does this situation affect each character's wishes?\")\n",
    "register_relation(X_WISHES, kind=\"social\")\n",
    "print(X_WISHES in EVENT_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mismayil/.pyenv/versions/3.8.12/envs/kogito/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge(head=\"h1\", relation=\"xWants\", tails=['hi', '', '  '])\n",
      "Knowledge(head=\"h2\", relation=\"xWants\", tails=['hi', 'ho', ' hah '])\n",
      "Knowledge(head=\"h3\", relation=\"xWants\", tails=['hi', '', ' huha '])\n",
      "Knowledge(head=\"h4\", relation=\"xWants\", tails=['', ' ', '  '])\n",
      "Knowledge(head=\"h1\", relation=\"xWants\", tails=['hi'])\n",
      "Knowledge(head=\"h2\", relation=\"xWants\", tails=['hi', 'ho', 'hah'])\n",
      "Knowledge(head=\"h3\", relation=\"xWants\", tails=['hi', 'huha'])\n"
     ]
    }
   ],
   "source": [
    "from kogito.core.knowledge import Knowledge, KnowledgeGraph\n",
    "\n",
    "kg1 = Knowledge(\"h1\", \"xWants\", [\"hi\", \"\", \"  \"])\n",
    "kg2 = Knowledge(\"h2\", \"xWants\", [\"hi\", \"ho\", \" hah \"])\n",
    "kg3 = Knowledge(\"h3\", \"xWants\", [\"hi\", \"\", \" huha \"])\n",
    "kg4 = Knowledge(\"h4\", \"xWants\", [\"\", \" \", \"  \"])\n",
    "\n",
    "kgraph = KnowledgeGraph([kg1, kg2, kg3, kg4])\n",
    "print(kgraph)\n",
    "kgraph.clean()\n",
    "print(kgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "98\n",
      "97\n",
      "96\n",
      "95\n",
      "94\n",
      "93\n",
      "92\n",
      "91\n",
      "90\n",
      "89\n",
      "88\n",
      "87\n",
      "86\n",
      "85\n",
      "84\n",
      "35\n",
      "34\n",
      "33\n",
      "32\n",
      "31\n",
      "30\n",
      "29\n",
      "28\n",
      "27\n",
      "26\n",
      "25\n",
      "24\n",
      "23\n",
      "22\n",
      "21\n",
      "20\n",
      "67\n",
      "66\n",
      "65\n",
      "64\n",
      "63\n",
      "62\n",
      "61\n",
      "60\n",
      "59\n",
      "58\n",
      "57\n",
      "56\n",
      "55\n",
      "54\n",
      "53\n",
      "52\n",
      "83\n",
      "82\n",
      "81\n",
      "80\n",
      "79\n",
      "78\n",
      "77\n",
      "76\n",
      "75\n",
      "74\n",
      "73\n",
      "72\n",
      "71\n",
      "70\n",
      "69\n",
      "68\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "51\n",
      "50\n",
      "49\n",
      "48\n",
      "47\n",
      "46\n",
      "45\n",
      "44\n",
      "43\n",
      "42\n",
      "41\n",
      "40\n",
      "39\n",
      "38\n",
      "37\n",
      "36\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from kogito.core.utils import SortishSampler\n",
    "\n",
    "ss = SortishSampler(list(range(100)), 16)\n",
    "\n",
    "for s in ss:\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kogito-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f24965dd94e4c0052d788733e7ddbb6e931f72d604403246d6e227e2d7fe7557"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
