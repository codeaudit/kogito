{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.38k/4.38k [00:00<00:00, 936kB/s]\n",
      "Downloading metadata: 100%|██████████| 2.04k/2.04k [00:00<00:00, 896kB/s]\n",
      "Downloading readme: 100%|██████████| 7.46k/7.46k [00:00<00:00, 2.69MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cc_news/plain_text to /Users/mismayil/.cache/huggingface/datasets/cc_news/plain_text/1.0.0/ae469e556251e6e7e20a789f93803c7de19d0c4311b6854ab072fecb4e401bd6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 845M/845M [00:41<00:00, 20.3MB/s] \n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cc_news downloaded and prepared to /Users/mismayil/.cache/huggingface/datasets/cc_news/plain_text/1.0.0/ae469e556251e6e7e20a789f93803c7de19d0c4311b6854ab072fecb4e401bd6. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cc_news = load_dataset(\"cc_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(cc_news[\"train\"], shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = next(iter(loader))\n",
    "\n",
    "len(samples[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/cc_news_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in samples[\"description\"] if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.85k/4.85k [00:00<00:00, 1.84MB/s]\n",
      "Downloading metadata: 100%|██████████| 2.49k/2.49k [00:00<00:00, 1.14MB/s]\n",
      "Downloading readme: 100%|██████████| 7.21k/7.21k [00:00<00:00, 2.31MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset daily_dialog/default to /Users/mismayil/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 4.48M/4.48M [00:01<00:00, 3.69MB/s]\n",
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset daily_dialog downloaded and prepared to /Users/mismayil/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "daily_dialog = load_dataset(\"daily_dialog\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['dialog', 'act', 'emotion'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(daily_dialog, shuffle=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog': [['Hey man , you wanna buy some weed ? ',\n",
       "   ' Some what ? ',\n",
       "   ' Weed ! You know ? Pot , Ganja , Mary Jane some chronic ! ',\n",
       "   ' Oh , umm , no thanks . ',\n",
       "   ' I also have blow if you prefer to do a few lines . ',\n",
       "   ' No , I am ok , really . ',\n",
       "   ' Come on man ! I even got dope and acid ! Try some ! ',\n",
       "   ' Do you really have all of these drugs ? Where do you get them from ? ',\n",
       "   ' I got my connections ! Just tell me what you want and I ’ ll even give you one ounce for free . ',\n",
       "   ' Sounds good ! Let ’ s see , I want . ',\n",
       "   ' Yeah ? ',\n",
       "   ' I want you to put your hands behind your head ! You are under arrest ! '],\n",
       "  ['The taxi drivers are on strike again . ',\n",
       "   ' What for ? ',\n",
       "   ' They want the government to reduce the price of the gasoline . ',\n",
       "   ' It is really a hot potato . ']],\n",
       " 'act': [[3, 2, 3, 4, 3, 4, 3, 2, 3, 4, 2, 3], [1, 2, 1, 1]],\n",
       " 'emotion': [[0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0], [0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_dialog[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_samples = [\"\".join(dialog) for dialog in daily_dialog[:50][\"dialog\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dialog_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dialog_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in dialog_samples if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.51k/6.51k [00:00<00:00, 2.33MB/s]\n",
      "Downloading metadata: 100%|██████████| 1.33k/1.33k [00:00<00:00, 459kB/s]\n",
      "No config specified, defaulting to: roc_stories/all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset roc_stories/all to /Users/mismayil/.cache/huggingface/datasets/wza___roc_stories/all/2.1.0/43e2851d9f31e08e4b2dd07a8057ed7a64cbb25cc7105d09856c14e638695506...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 13.1M/13.1M [00:01<00:00, 10.8MB/s]\n",
      "Downloading data: 100%|██████████| 14.5M/14.5M [00:01<00:00, 11.8MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:05<00:00,  5.99s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 320.00it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset roc_stories downloaded and prepared to /Users/mismayil/.cache/huggingface/datasets/wza___roc_stories/all/2.1.0/43e2851d9f31e08e4b2dd07a8057ed7a64cbb25cc7105d09856c14e638695506. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 113.57it/s]\n"
     ]
    }
   ],
   "source": [
    "roc_stories = load_dataset(\"wza/roc_stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['storyid', 'storytitle', 'sentence1', 'sentence2', 'sentence3', 'sentence4', 'sentence5'],\n",
       "        num_rows: 98161\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_samples = roc_stories[\"train\"][:50]\n",
    "roc_samples = [\" \".join(sample) for sample in zip(roc_samples[\"sentence1\"], roc_samples[\"sentence2\"], roc_samples[\"sentence3\"], roc_samples[\"sentence4\"], roc_samples[\"sentence5\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Dan's parents were overweight. Dan was overweight as well. The doctors told his parents it was unhealthy. His parents understood and decided to make a change. They got themselves and Dan on a diet.\",\n",
       " \"Carrie had just learned how to ride a bike. She didn't have a bike of her own. Carrie would sneak rides on her sister's bike. She got nervous on a hill and crashed into a wall. The bike frame bent and Carrie got a deep gash on her leg.\",\n",
       " \"Morgan enjoyed long walks on the beach. She and her boyfriend decided to go for a long walk. After walking for over a mile, something happened. Morgan decided to propose to her boyfriend. Her boyfriend was upset he didn't propose to her first.\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_samples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/story_samples.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([sample for sample in roc_samples if sample.strip()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonX nsubj []\n",
      "falls ROOT [PersonX, in, with]\n",
      "in prep [love]\n",
      "love pobj []\n",
      "with prep [PersonY]\n",
      "PersonY pobj []\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "text = \"PersonX falls in love with PersonY\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[to fall]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kogito.core.processors.head import NounPhraseHeadExtractor, VerbPhraseHeadExtractor\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ext = NounPhraseHeadExtractor(\"ext\", nlp)\n",
    "vext = VerbPhraseHeadExtractor(\"vext\", nlp)\n",
    "vext.extract(\"PersonX falls in love with PersonY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting knowledge heads...\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "\n",
    "# Initialize inference module with a spacy language pipeline\n",
    "csi = CommonsenseInference(language=\"en_core_web_sm\")\n",
    "\n",
    "# Run inference\n",
    "text = \"PersonX becomes a great basketball player\"\n",
    "kgraph = csi.infer(text, match_relations=False)\n",
    "\n",
    "# Save output knowledge graph to JSON file\n",
    "kgraph.to_jsonl(\"results/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from kogito.inference import CommonsenseInference\n",
    "from kogito.core.knowledge import KnowledgeGraph\n",
    "from kogito.models.gpt3.zeroshot import GPT3Zeroshot\n",
    "from kogito.core.relation import KnowledgeRelation, register_relation, EVENT_RELATIONS\n",
    "import time, os\n",
    "\n",
    "# csi = CommonsenseInference()\n",
    "# csi.remove_processor(\"simple_relation_matcher\")\n",
    "\n",
    "def x_wishes_verbalizer(head, **kwargs):\n",
    "   # index will be passed from the model\n",
    "   # so that we can enumerate samples which helps with inference\n",
    "   index = kwargs.get(\"index\")\n",
    "   index_txt = f\"{index}\" if index is not None else \"\"\n",
    "   return f\"Situation {index_txt}: {head}\\nWishes: As a result, PersonX wishes\"\n",
    "\n",
    "X_WISHES = KnowledgeRelation(\"xWishes\",\n",
    "                             verbalizer=x_wishes_verbalizer,\n",
    "                             prompt=\"How does this situation affect each character's wishes?\")\n",
    "register_relation(X_WISHES, kind=\"social\")\n",
    "print(X_WISHES in EVENT_RELATIONS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78e267dbbd536cf72b9151fa10598d02f0742e0d77c5a78f8f9ba9a5d38a282d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
