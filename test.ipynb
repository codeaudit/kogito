{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DebertaV2ForSequenceClassification, DebertaV2Tokenizer\n",
    "\n",
    "NARRATIVE_SEP_TOKEN = \"<n_sep>\"\n",
    "FACT_SEP_TOKEN = \"<f_sep>\"\n",
    "\n",
    "RELATION_VERBALIZER = {\"AtLocation\": \"located or found at/in/on\",\n",
    "                       \"CapableOf\": \"is/are capable of\",\n",
    "                       \"Causes\": \"causes\",\n",
    "                       \"CausesDesire\": \"makes someone want\",\n",
    "                       \"CreatedBy\": \"is created by\",\n",
    "                       \"Desires\": \"desires\",\n",
    "                       \"HasA\": \"has, possesses or contains\",\n",
    "                       \"HasFirstSubevent\": \"begins with the event/action\",\n",
    "                       \"HasLastSubevent\": \"ends with the event/action\",\n",
    "                       \"HasPrerequisite\": \"to do this, one requires\",\n",
    "                       \"HasProperty\": \"can be characterized by being/having\",\n",
    "                       \"HasSubEvent\": \"includes the event/action\",\n",
    "                       \"HinderedBy\": \"can be hindered by\",\n",
    "                       \"InstanceOf\": \"is an example/instance of\",\n",
    "                       \"isAfter\": \"happens after\",\n",
    "                       \"isBefore\": \"happens before\",\n",
    "                       \"isFilledBy\": \"___ can be filled by\",\n",
    "                       \"MadeOf\": \"is made of\",\n",
    "                       \"MadeUpOf\": \"made (up) of\",\n",
    "                       \"MotivatedByGoal\": \"is a step towards accomplishing the goal\",\n",
    "                       \"NotDesires\": \"do(es) not desire\",\n",
    "                       \"ObjectUse\": \"used for\",\n",
    "                       \"UsedFor\": \"used for\",\n",
    "                       \"oEffect\": \"as a result, PersonY or others will\",\n",
    "                       \"oReact\": \"as a result, PersonY or others feels\",\n",
    "                       \"oWant\": \"as a result, PersonY or others wants\",\n",
    "                       \"PartOf\": \"is a part of\",\n",
    "                       \"ReceivesAction\": \"can receive or be affected by the action\",\n",
    "                       \"xAttr\": \"PersonX is seen as\",\n",
    "                       \"xEffect\": \"as a result, PersonX will\",\n",
    "                       \"xIntent\": \"because PersonX wants\",\n",
    "                       \"xNeed\": \"but before, PersonX needs\",\n",
    "                       \"xReact\": \"as a result, PersonX feels\",\n",
    "                       \"xReason\": \"because\",\n",
    "                       \"xWant\": \"as a result, PersonX wants\"}\n",
    "\n",
    "tokenizer_path = model_path = \"ComFact_DeBERTa/deberta-large-nlu-fact_full/checkpoint-236560\"\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(tokenizer_path)\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "narrative_sep_id = tokenizer.convert_tokens_to_ids(NARRATIVE_SEP_TOKEN)\n",
    "fact_sep_id = tokenizer.convert_tokens_to_ids(FACT_SEP_TOKEN)\n",
    "\n",
    "context = [\n",
    "      \"hey , i am in a lady motorcycle club and i love to drive fast\",\n",
    "      \"i am married to a wife beater and have two kids\",\n",
    "      \"well do you want me to come beat him ? i have never lost a fight\",\n",
    "      \"then we can go shopping ! i love shopping . i am a lifestyle shop blogger .\",\n",
    "      \"well there you go lol and your kids would enjoy checking my tatts i have got 12\",\n",
    "      \"i am very attractive . i was a cheerleader in high school . maybe we can go on a date\",\n",
    "      \"u like women too ? did not know that\",\n",
    "      \"got to get away from my husband i live in florida . celebration florida come meet me\",\n",
    "      \"i just drove 20 mins this morning at 208 mph i can get there fast\",\n",
    "      \"i will leave my kids never liked them lets do this !\",\n",
    "      \"sounds like a plan i will be there soon you can hop on my bike\",\n",
    "      \"the we can ride off into the sunset just like lovers in a novel\",\n",
    "      \"well then pack your bags\",\n",
    "      \"yay i am so excited i think i will burn the house down before i leave .\"\n",
    "    ]\n",
    "# fact = {\"head\": \"PersonX drives ___ fast\", \"relation\": \"xIntent\", \"tail\": \"to get a thrill\"}\n",
    "fact = {\"head\": \"PersonX drives ___ fast\", \"relation\": \"oWant\", \"tail\": \"to call the police\"}\n",
    "fact[\"relation\"] = RELATION_VERBALIZER[fact[\"relation\"]]\n",
    "fact[\"head\"] = fact[\"head\"].lower()\n",
    "fact[\"tail\"] = fact[\"tail\"].lower()\n",
    "\n",
    "context_ids = [tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent)) for sent in context]\n",
    "fact_ids = [tokenizer.convert_tokens_to_ids(tokenizer.tokenize(fact[key])) for key in [\"head\", \"relation\", \"tail\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128001, 128002)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative_sep_id, fact_sep_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[604, 982, 5328, 5179, 616, 616, 1274],\n",
       " [401, 12590, 2087, 1654],\n",
       " [264, 350, 266, 14713]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "context_ids_with_sep = list(chain(*[ids+[narrative_sep_id] for ids in context_ids[:-1]], context_ids[-1]))\n",
    "fact_ids_with_sep = list(chain(*[ids+[fact_sep_id] for ids in fact_ids[:-1]], fact_ids[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.build_inputs_with_special_tokens(context_ids_with_sep, fact_ids_with_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 11187,\n",
       " 366,\n",
       " 584,\n",
       " 481,\n",
       " 267,\n",
       " 266,\n",
       " 4396,\n",
       " 8209,\n",
       " 1788,\n",
       " 263,\n",
       " 584,\n",
       " 472,\n",
       " 264,\n",
       " 1168,\n",
       " 1274,\n",
       " 128001,\n",
       " 584,\n",
       " 481,\n",
       " 2410,\n",
       " 264,\n",
       " 266,\n",
       " 1553,\n",
       " 56596,\n",
       " 263,\n",
       " 286,\n",
       " 375,\n",
       " 978,\n",
       " 128001,\n",
       " 371,\n",
       " 333,\n",
       " 274,\n",
       " 409,\n",
       " 351,\n",
       " 264,\n",
       " 488,\n",
       " 2584,\n",
       " 417,\n",
       " 1102,\n",
       " 584,\n",
       " 286,\n",
       " 518,\n",
       " 1125,\n",
       " 266,\n",
       " 1801,\n",
       " 128001,\n",
       " 393,\n",
       " 301,\n",
       " 295,\n",
       " 424,\n",
       " 2017,\n",
       " 1084,\n",
       " 584,\n",
       " 472,\n",
       " 2017,\n",
       " 323,\n",
       " 584,\n",
       " 481,\n",
       " 266,\n",
       " 3444,\n",
       " 1638,\n",
       " 8874,\n",
       " 323,\n",
       " 128001,\n",
       " 371,\n",
       " 343,\n",
       " 274,\n",
       " 424,\n",
       " 8878,\n",
       " 263,\n",
       " 290,\n",
       " 978,\n",
       " 338,\n",
       " 929,\n",
       " 4155,\n",
       " 312,\n",
       " 33276,\n",
       " 297,\n",
       " 268,\n",
       " 584,\n",
       " 286,\n",
       " 519,\n",
       " 621,\n",
       " 128001,\n",
       " 584,\n",
       " 481,\n",
       " 379,\n",
       " 3851,\n",
       " 323,\n",
       " 584,\n",
       " 284,\n",
       " 266,\n",
       " 43701,\n",
       " 267,\n",
       " 459,\n",
       " 563,\n",
       " 323,\n",
       " 1461,\n",
       " 301,\n",
       " 295,\n",
       " 424,\n",
       " 277,\n",
       " 266,\n",
       " 1043,\n",
       " 128001,\n",
       " 3636,\n",
       " 334,\n",
       " 694,\n",
       " 461,\n",
       " 1102,\n",
       " 464,\n",
       " 298,\n",
       " 391,\n",
       " 272,\n",
       " 128001,\n",
       " 519,\n",
       " 264,\n",
       " 350,\n",
       " 557,\n",
       " 292,\n",
       " 312,\n",
       " 1745,\n",
       " 584,\n",
       " 685,\n",
       " 267,\n",
       " 29983,\n",
       " 323,\n",
       " 4630,\n",
       " 29983,\n",
       " 488,\n",
       " 957,\n",
       " 351,\n",
       " 128001,\n",
       " 584,\n",
       " 348,\n",
       " 5066,\n",
       " 602,\n",
       " 12178,\n",
       " 291,\n",
       " 1066,\n",
       " 288,\n",
       " 23299,\n",
       " 9353,\n",
       " 584,\n",
       " 295,\n",
       " 350,\n",
       " 343,\n",
       " 1274,\n",
       " 128001,\n",
       " 584,\n",
       " 296,\n",
       " 1021,\n",
       " 312,\n",
       " 978,\n",
       " 518,\n",
       " 3172,\n",
       " 349,\n",
       " 4573,\n",
       " 333,\n",
       " 291,\n",
       " 1084,\n",
       " 128001,\n",
       " 2163,\n",
       " 334,\n",
       " 266,\n",
       " 741,\n",
       " 584,\n",
       " 296,\n",
       " 282,\n",
       " 343,\n",
       " 950,\n",
       " 274,\n",
       " 295,\n",
       " 8761,\n",
       " 277,\n",
       " 312,\n",
       " 2772,\n",
       " 128001,\n",
       " 262,\n",
       " 301,\n",
       " 295,\n",
       " 2224,\n",
       " 442,\n",
       " 352,\n",
       " 262,\n",
       " 9606,\n",
       " 348,\n",
       " 334,\n",
       " 7462,\n",
       " 267,\n",
       " 266,\n",
       " 2626,\n",
       " 128001,\n",
       " 371,\n",
       " 393,\n",
       " 3105,\n",
       " 290,\n",
       " 3713,\n",
       " 128001,\n",
       " 39390,\n",
       " 584,\n",
       " 481,\n",
       " 324,\n",
       " 2199,\n",
       " 584,\n",
       " 428,\n",
       " 584,\n",
       " 296,\n",
       " 5134,\n",
       " 262,\n",
       " 669,\n",
       " 444,\n",
       " 416,\n",
       " 584,\n",
       " 1021,\n",
       " 323,\n",
       " 2,\n",
       " 604,\n",
       " 982,\n",
       " 5328,\n",
       " 5179,\n",
       " 616,\n",
       " 616,\n",
       " 1274,\n",
       " 128002,\n",
       " 401,\n",
       " 12590,\n",
       " 2087,\n",
       " 1654,\n",
       " 128002,\n",
       " 264,\n",
       " 350,\n",
       " 266,\n",
       " 14713,\n",
       " 2]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "output = model(torch.tensor(input_ids).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.9805,  1.0133]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1199, 0.8801]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(output.logits, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kogito')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e80d669f60bd34413df3f847d16a09f3fef6827513c4f925b04d67ca5f47b92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
